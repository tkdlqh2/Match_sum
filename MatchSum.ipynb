{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MatchSum.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMULG/uMSIVxURWzFGG+gge",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "27c12e6702304c48bc881ce6d86cfedd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_aa89508f78224a8d9b2ab525820021b4",
              "IPY_MODEL_3395363ccd624d7fb7516573b58fed6d",
              "IPY_MODEL_1192f5024d19473c8ec884f66e4fb0da"
            ],
            "layout": "IPY_MODEL_3f37563126604e2fa7fe7dde8754dd39"
          }
        },
        "aa89508f78224a8d9b2ab525820021b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bda286eccf334dffac9fcd43599f3d70",
            "placeholder": "​",
            "style": "IPY_MODEL_41ca4cc3e7d94a5ab11a0f878d6863c0",
            "value": "Downloading: 100%"
          }
        },
        "3395363ccd624d7fb7516573b58fed6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4cbd8a78490640e8a85e6f97072986a0",
            "max": 545,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_354601429e864562b15c4d6fc076794e",
            "value": 545
          }
        },
        "1192f5024d19473c8ec884f66e4fb0da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ab01d3d62124074ae7622824723c1f3",
            "placeholder": "​",
            "style": "IPY_MODEL_84c8bef952da46d3b79559a591062bb2",
            "value": " 545/545 [00:00&lt;00:00, 7.26kB/s]"
          }
        },
        "3f37563126604e2fa7fe7dde8754dd39": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bda286eccf334dffac9fcd43599f3d70": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "41ca4cc3e7d94a5ab11a0f878d6863c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4cbd8a78490640e8a85e6f97072986a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "354601429e864562b15c4d6fc076794e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6ab01d3d62124074ae7622824723c1f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "84c8bef952da46d3b79559a591062bb2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "92f0a61cb84340aab1ec58c23d12a63e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_96755a28768347308d94cb38b2c43fbd",
              "IPY_MODEL_5b1c99b973bc4eaead9995a0109f8502",
              "IPY_MODEL_271024e2e6124f05b3a9d763ec200331"
            ],
            "layout": "IPY_MODEL_3f68d91fcc674a3ba48b6c8ab0646a38"
          }
        },
        "96755a28768347308d94cb38b2c43fbd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b34567df09c149fc9418215944cb2a73",
            "placeholder": "​",
            "style": "IPY_MODEL_8569bc15c37f42498d22cd87f2e6d39f",
            "value": "Downloading: 100%"
          }
        },
        "5b1c99b973bc4eaead9995a0109f8502": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cce7ca8acd704173bbab257788864b28",
            "max": 248477,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_557f5fe53c4346e0afce160f651947f7",
            "value": 248477
          }
        },
        "271024e2e6124f05b3a9d763ec200331": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_76e0c1f7b7d140a5a9e11b8312962f4f",
            "placeholder": "​",
            "style": "IPY_MODEL_44110f8d4f6b48bbafc64d2a9ef6134f",
            "value": " 248k/248k [00:00&lt;00:00, 308kB/s]"
          }
        },
        "3f68d91fcc674a3ba48b6c8ab0646a38": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b34567df09c149fc9418215944cb2a73": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8569bc15c37f42498d22cd87f2e6d39f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cce7ca8acd704173bbab257788864b28": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "557f5fe53c4346e0afce160f651947f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "76e0c1f7b7d140a5a9e11b8312962f4f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "44110f8d4f6b48bbafc64d2a9ef6134f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "83982aea703e4824b67a07392c10bd49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_aff29cfc58c843c689ae6dc4d4e6a954",
              "IPY_MODEL_f192ca7924e6472584f48d90e68a6ffb",
              "IPY_MODEL_08032619e8d7424da27d3f3f2463edf5"
            ],
            "layout": "IPY_MODEL_fdffb23f7fa6489c923dbba953f915e7"
          }
        },
        "aff29cfc58c843c689ae6dc4d4e6a954": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_08c5f85a60754a2d9355292b8453c3d4",
            "placeholder": "​",
            "style": "IPY_MODEL_2d61e46eac3e4b69abbd1398d9196ad1",
            "value": "Downloading: 100%"
          }
        },
        "f192ca7924e6472584f48d90e68a6ffb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4f1dac26d6584af8a4a25aba6592637c",
            "max": 751504,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_185fe653768f47179ca2c0b53996fcd3",
            "value": 751504
          }
        },
        "08032619e8d7424da27d3f3f2463edf5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9996ac88473f43af8c2a741cd8169d3b",
            "placeholder": "​",
            "style": "IPY_MODEL_7e4a4ee146144ec6ac7ea6de6c230f2a",
            "value": " 752k/752k [00:01&lt;00:00, 573kB/s]"
          }
        },
        "fdffb23f7fa6489c923dbba953f915e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "08c5f85a60754a2d9355292b8453c3d4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d61e46eac3e4b69abbd1398d9196ad1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4f1dac26d6584af8a4a25aba6592637c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "185fe653768f47179ca2c0b53996fcd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9996ac88473f43af8c2a741cd8169d3b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e4a4ee146144ec6ac7ea6de6c230f2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2ac65f8e69f74cb1a38e65ca47c1d91e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cd2c5a56288c4ccfafafa269f7956c9c",
              "IPY_MODEL_1111a0c1490c4c559bf94b34e1391ae4",
              "IPY_MODEL_d23b7efa597949ec9cd7f41dc0f6b942"
            ],
            "layout": "IPY_MODEL_6a9e2983d6f340d398848d1fa51982e9"
          }
        },
        "cd2c5a56288c4ccfafafa269f7956c9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c752a5a37f204a31ab8f960ce810ed72",
            "placeholder": "​",
            "style": "IPY_MODEL_580a05e98ed048b397be96840050fc3b",
            "value": "Downloading: 100%"
          }
        },
        "1111a0c1490c4c559bf94b34e1391ae4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5181b96cd20b43cab7e7d66f157daeb2",
            "max": 173,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c21c68da638a4a678903d819433a5e4c",
            "value": 173
          }
        },
        "d23b7efa597949ec9cd7f41dc0f6b942": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3aba0867f33e4c4ca8662e46afcf272d",
            "placeholder": "​",
            "style": "IPY_MODEL_c99c428b2fc9446389bf298d3e481c7e",
            "value": " 173/173 [00:00&lt;00:00, 7.00kB/s]"
          }
        },
        "6a9e2983d6f340d398848d1fa51982e9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c752a5a37f204a31ab8f960ce810ed72": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "580a05e98ed048b397be96840050fc3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5181b96cd20b43cab7e7d66f157daeb2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c21c68da638a4a678903d819433a5e4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3aba0867f33e4c4ca8662e46afcf272d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c99c428b2fc9446389bf298d3e481c7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "25e5fb460cf44c319f3b6b21ae13d2c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a4975bcc02184ed99036b539bbeb74fa",
              "IPY_MODEL_8282563d0cb34dffad962f70f25b0282",
              "IPY_MODEL_0d57f32ad0b84401b1dc3a1545cb28f0"
            ],
            "layout": "IPY_MODEL_47c1d8d62a1140b1a9094c26d68740e1"
          }
        },
        "a4975bcc02184ed99036b539bbeb74fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6e0c430b6c1b4a2aab8885a09c9052aa",
            "placeholder": "​",
            "style": "IPY_MODEL_173eaeeb934e4239b637b69d5e9b7c8e",
            "value": "Downloading: 100%"
          }
        },
        "8282563d0cb34dffad962f70f25b0282": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e63d3e0d2a544499bf93de03a0e632e1",
            "max": 375,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6e6df246896c43f5a217d5081824d98b",
            "value": 375
          }
        },
        "0d57f32ad0b84401b1dc3a1545cb28f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8a8ca2ee00944c328315477924d569e8",
            "placeholder": "​",
            "style": "IPY_MODEL_d44cd6e09b614d018891a220b824f144",
            "value": " 375/375 [00:00&lt;00:00, 16.4kB/s]"
          }
        },
        "47c1d8d62a1140b1a9094c26d68740e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e0c430b6c1b4a2aab8885a09c9052aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "173eaeeb934e4239b637b69d5e9b7c8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e63d3e0d2a544499bf93de03a0e632e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e6df246896c43f5a217d5081824d98b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8a8ca2ee00944c328315477924d569e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d44cd6e09b614d018891a220b824f144": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "889dd441781e43338eebb6f2df6abda3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_71314f261f0b4585ba22eadf046f0f86",
              "IPY_MODEL_dcc8354e36bc45d28d2963b286b212d6",
              "IPY_MODEL_6bfd9b0215e5463a88f92210166c0f36"
            ],
            "layout": "IPY_MODEL_0e2c12a376c3441f9d109ff04c2e6700"
          }
        },
        "71314f261f0b4585ba22eadf046f0f86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_47fe9495791d42faa3303827937362c9",
            "placeholder": "​",
            "style": "IPY_MODEL_0c75df9ab030491dbe6454cea87ad0bf",
            "value": "Downloading: 100%"
          }
        },
        "dcc8354e36bc45d28d2963b286b212d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b8484c50855f479d8101f7bbc4dcc3e5",
            "max": 272545970,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_357472a371c1409c98b79edca7c8126f",
            "value": 272545970
          }
        },
        "6bfd9b0215e5463a88f92210166c0f36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a4d8097a6931489b9326cd0a28500181",
            "placeholder": "​",
            "style": "IPY_MODEL_2bc96adfd5484b95a5f7464b7d1cb53c",
            "value": " 273M/273M [00:05&lt;00:00, 29.0MB/s]"
          }
        },
        "0e2c12a376c3441f9d109ff04c2e6700": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "47fe9495791d42faa3303827937362c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c75df9ab030491dbe6454cea87ad0bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b8484c50855f479d8101f7bbc4dcc3e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "357472a371c1409c98b79edca7c8126f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a4d8097a6931489b9326cd0a28500181": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2bc96adfd5484b95a5f7464b7d1cb53c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tkdlqh2/Match_sum/blob/main/MatchSum.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 설정 + 필요한 모델 다운로드"
      ],
      "metadata": {
        "id": "hxa-HJR8oohX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m6Y2gI7an3tP",
        "outputId": "ccb8bf03-2ed0-42b3-816e-79682dc9b4b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting konlpy\n",
            "  Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 19.4 MB 8.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.2.6)\n",
            "Collecting JPype1>=0.7.0\n",
            "  Downloading JPype1-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (448 kB)\n",
            "\u001b[K     |████████████████████████████████| 448 kB 70.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (4.1.1)\n",
            "Installing collected packages: JPype1, konlpy\n",
            "Successfully installed JPype1-1.3.0 konlpy-0.6.0\n"
          ]
        }
      ],
      "source": [
        "!pip install konlpy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/SKT-AI/KoBART #egg=kobart"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w0Y5EhDuoQfi",
        "outputId": "f804a4da-fe4d-4040-d4ed-19df1274f1be"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/SKT-AI/KoBART\n",
            "  Cloning https://github.com/SKT-AI/KoBART to /tmp/pip-req-build-qqveoye1\n",
            "  Running command git clone -q https://github.com/SKT-AI/KoBART /tmp/pip-req-build-qqveoye1\n",
            "Collecting boto3\n",
            "  Downloading boto3-1.21.46-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 7.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from kobart==0.5.1) (1.3.5)\n",
            "Collecting pytorch-lightning==1.2.1\n",
            "  Downloading pytorch_lightning-1.2.1-py3-none-any.whl (814 kB)\n",
            "\u001b[K     |████████████████████████████████| 814 kB 56.5 MB/s \n",
            "\u001b[?25hCollecting torch==1.7.1\n",
            "  Downloading torch-1.7.1-cp37-cp37m-manylinux1_x86_64.whl (776.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 776.8 MB 16 kB/s \n",
            "\u001b[?25hCollecting transformers==4.3.3\n",
            "  Downloading transformers-4.3.3-py3-none-any.whl (1.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.9 MB 40.1 MB/s \n",
            "\u001b[?25hCollecting PyYAML!=5.4.*,>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 70.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorboard>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.2.1->kobart==0.5.1) (2.8.0)\n",
            "Collecting future>=0.17.1\n",
            "  Downloading future-0.18.2.tar.gz (829 kB)\n",
            "\u001b[K     |████████████████████████████████| 829 kB 63.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.2.1->kobart==0.5.1) (4.64.0)\n",
            "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.2.1->kobart==0.5.1) (1.21.6)\n",
            "Collecting fsspec[http]>=0.8.1\n",
            "  Downloading fsspec-2022.3.0-py3-none-any.whl (136 kB)\n",
            "\u001b[K     |████████████████████████████████| 136 kB 87.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.7.1->kobart==0.5.1) (4.1.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==4.3.3->kobart==0.5.1) (21.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.3.3->kobart==0.5.1) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.3.3->kobart==0.5.1) (3.6.0)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 79.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.3.3->kobart==0.5.1) (4.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.3.3->kobart==0.5.1) (2.23.0)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.49-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 72.6 MB/s \n",
            "\u001b[?25hCollecting aiohttp\n",
            "  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 60.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.2.1->kobart==0.5.1) (1.35.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.2.1->kobart==0.5.1) (0.37.1)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.2.1->kobart==0.5.1) (1.44.0)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.2.1->kobart==0.5.1) (3.17.3)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.2.1->kobart==0.5.1) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.2.1->kobart==0.5.1) (3.3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.2.1->kobart==0.5.1) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.2.1->kobart==0.5.1) (1.8.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.2.1->kobart==0.5.1) (0.4.6)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.2.1->kobart==0.5.1) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.2.1->kobart==0.5.1) (57.4.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.4->tensorboard>=2.2.0->pytorch-lightning==1.2.1->kobart==0.5.1) (1.15.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.2.1->kobart==0.5.1) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.2.1->kobart==0.5.1) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.2.1->kobart==0.5.1) (4.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning==1.2.1->kobart==0.5.1) (1.3.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.3.3->kobart==0.5.1) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.2.1->kobart==0.5.1) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.3.3->kobart==0.5.1) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.3.3->kobart==0.5.1) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.3.3->kobart==0.5.1) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.3.3->kobart==0.5.1) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning==1.2.1->kobart==0.5.1) (3.2.0)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
            "\u001b[K     |████████████████████████████████| 271 kB 85.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]>=0.8.1->pytorch-lightning==1.2.1->kobart==0.5.1) (21.4.0)\n",
            "Collecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]>=0.8.1->pytorch-lightning==1.2.1->kobart==0.5.1) (2.0.12)\n",
            "Collecting asynctest==0.13.0\n",
            "  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "\u001b[K     |████████████████████████████████| 144 kB 69.6 MB/s \n",
            "\u001b[?25hCollecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n",
            "\u001b[K     |████████████████████████████████| 94 kB 4.6 MB/s \n",
            "\u001b[?25hCollecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
            "Collecting botocore<1.25.0,>=1.24.46\n",
            "  Downloading botocore-1.24.46-py3-none-any.whl (8.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.7 MB 51.8 MB/s \n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1\n",
            "  Downloading jmespath-1.0.0-py3-none-any.whl (23 kB)\n",
            "Collecting s3transfer<0.6.0,>=0.5.0\n",
            "  Downloading s3transfer-0.5.2-py3-none-any.whl (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 11.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.25.0,>=1.24.46->boto3->kobart==0.5.1) (2.8.2)\n",
            "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 86.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==4.3.3->kobart==0.5.1) (3.0.8)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->kobart==0.5.1) (2022.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.3.3->kobart==0.5.1) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.3.3->kobart==0.5.1) (7.1.2)\n",
            "Building wheels for collected packages: kobart, future\n",
            "  Building wheel for kobart (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kobart: filename=kobart-0.5.1-py3-none-any.whl size=9562 sha256=82fade6a81d15a60caf23b234a4e971a7c36cb1bbe79d2363aee0bc51d0341bd\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-29djdp6a/wheels/6e/55/c4/bd4fede223bc304089ac8da2a2099a69db3fcd4b0e853383f5\n",
            "  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491070 sha256=bdf541b7ec01bff06f1f4a72c1d9d540b9bd59d6b58e390b9991b0a9bdcf22c0\n",
            "  Stored in directory: /root/.cache/pip/wheels/56/b0/fe/4410d17b32f1f0c3cf54cdfb2bc04d7b4b8f4ae377e2229ba0\n",
            "Successfully built kobart future\n",
            "Installing collected packages: urllib3, multidict, frozenlist, yarl, jmespath, asynctest, async-timeout, aiosignal, fsspec, botocore, aiohttp, torch, tokenizers, sacremoses, s3transfer, PyYAML, future, transformers, pytorch-lightning, boto3, kobart\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.10.0+cu111\n",
            "    Uninstalling torch-1.10.0+cu111:\n",
            "      Successfully uninstalled torch-1.10.0+cu111\n",
            "  Attempting uninstall: PyYAML\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Attempting uninstall: future\n",
            "    Found existing installation: future 0.16.0\n",
            "    Uninstalling future-0.16.0:\n",
            "      Successfully uninstalled future-0.16.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.11.1+cu111 requires torch==1.10.0, but you have torch 1.7.1 which is incompatible.\n",
            "torchtext 0.11.0 requires torch==1.10.0, but you have torch 1.7.1 which is incompatible.\n",
            "torchaudio 0.10.0+cu111 requires torch==1.10.0, but you have torch 1.7.1 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed PyYAML-6.0 aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.2 asynctest-0.13.0 boto3-1.21.46 botocore-1.24.46 frozenlist-1.3.0 fsspec-2022.3.0 future-0.18.2 jmespath-1.0.0 kobart-0.5.1 multidict-6.0.2 pytorch-lightning-1.2.1 s3transfer-0.5.2 sacremoses-0.0.49 tokenizers-0.10.3 torch-1.7.1 transformers-4.3.3 urllib3-1.25.11 yarl-1.7.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NoMZYlwOoR8f",
        "outputId": "b0db4603-c727-402e-86a8-ed1045e388e7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.3.3)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.49)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (3.0.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.25.11)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ga4nRIdHoekP",
        "outputId": "14ea4820-6d48-4e51-a265-de59a50c114a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wandb\n",
            "  Downloading wandb-0.12.15-py2.py3-none-any.whl (1.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8 MB 8.9 MB/s \n",
            "\u001b[?25hCollecting sentry-sdk>=1.0.0\n",
            "  Downloading sentry_sdk-1.5.10-py2.py3-none-any.whl (144 kB)\n",
            "\u001b[K     |████████████████████████████████| 144 kB 88.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.17.3)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n",
            "Collecting shortuuid>=0.5.0\n",
            "  Downloading shortuuid-1.0.8-py3-none-any.whl (9.5 kB)\n",
            "Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (6.0)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n",
            "Collecting setproctitle\n",
            "  Downloading setproctitle-1.2.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29 kB)\n",
            "Collecting docker-pycreds>=0.4.0\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Collecting pathtools\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "Collecting GitPython>=1.0.0\n",
            "  Downloading GitPython-3.1.27-py3-none-any.whl (181 kB)\n",
            "\u001b[K     |████████████████████████████████| 181 kB 67.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.8.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (4.1.1)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 2.3 MB/s \n",
            "\u001b[?25hCollecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (1.25.11)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
            "Building wheels for collected packages: pathtools\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8806 sha256=b29e8d1f123e42ce21f87d59458f34e3a697309f542502e9ca0f30213ae9a6a2\n",
            "  Stored in directory: /root/.cache/pip/wheels/3e/31/09/fa59cef12cdcfecc627b3d24273699f390e71828921b2cbba2\n",
            "Successfully built pathtools\n",
            "Installing collected packages: smmap, gitdb, shortuuid, setproctitle, sentry-sdk, pathtools, GitPython, docker-pycreds, wandb\n",
            "Successfully installed GitPython-3.1.27 docker-pycreds-0.4.0 gitdb-4.0.9 pathtools-0.1.2 sentry-sdk-1.5.10 setproctitle-1.2.3 shortuuid-1.0.8 smmap-5.0.0 wandb-0.12.15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import os \n",
        "import sys\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "tqdm.pandas()\n",
        "import json\n",
        "import wandb\n",
        "\n",
        "from google.colab import drive\n",
        "import re\n",
        "from konlpy.tag import Okt\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "from itertools import combinations\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import AdamW\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "from torch.utils.data import Dataset, DataLoader,random_split\n",
        "\n",
        "from kobart import get_pytorch_kobart_model, get_kobart_tokenizer\n",
        "from transformers import AutoModel, AutoTokenizer, BartModel"
      ],
      "metadata": {
        "id": "CkMBmsmkohc5"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# seed\n",
        "seed = 7777\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed)\n",
        "# device type\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(f\"# available GPUs : {torch.cuda.device_count()}\")\n",
        "    print(f\"GPU name : {torch.cuda.get_device_name()}\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wEYG6QAMokpO",
        "outputId": "06e255fd-3a31-4f7f-d1c0-b548e001e6e1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# available GPUs : 1\n",
            "GPU name : Tesla P100-PCIE-16GB\n",
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 원본 데이터 불러오기"
      ],
      "metadata": {
        "id": "DKXNGIfzonDh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount(\"/content/drive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0v8r-sJHolkV",
        "outputId": "380e377d-ec71-43bd-b21f-7219a7ec728b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/drive/MyDrive/Summary_task/Training/train_original.json\") as f:\n",
        "  json_data = json.load(f)"
      ],
      "metadata": {
        "id": "46VK_6JjowUJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "documents = json_data[\"documents\"]"
      ],
      "metadata": {
        "id": "yVk77q_Eo0EE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(columns=['TITLE','ABS_SUM','CONTENT'])\n",
        "\n",
        "for document in tqdm(documents[:20000]):\n",
        "    stc_list = []\n",
        "    \n",
        "    for j in document['text'][2:]:\n",
        "        if j == [] : continue\n",
        "        stc_list.append(j[0][\"sentence\"])\n",
        "            \n",
        "    df = df.append(pd.DataFrame([[document['title'],document['abstractive'][0],stc_list]], columns=['TITLE','ABS_SUM','CONTENT']), ignore_index=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NyVShvPoy5Qi",
        "outputId": "665e612b-6d74-4936-b884-9e300766998c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20000/20000 [00:32<00:00, 614.52it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "8fNaSqbv8lvm",
        "outputId": "4ccb0a5d-ed57-4853-d729-483aadde30af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                           TITLE  \\\n",
              "0         논 타작물 재배, 2월 말까지 신청하세요   \n",
              "1  여수시, 컬러빌리지 마무리...‘색채와 빛’도시 완성   \n",
              "2        “새해 정기 받고 올해는 반드시 일내자!”   \n",
              "3          농업인 역량 강화, 새해 실용교육 실시   \n",
              "4          타이완 크루즈관광객 4천여명‘전남’온다   \n",
              "\n",
              "                                             ABS_SUM  \\\n",
              "0  전라남도가 쌀 과잉문제를 근본적으로 해결하기 위해 올해부터 벼를 심었던 논에 벼 대...   \n",
              "1  여수시는 컬러빌리지 사업에 8억원을 투입하여 ‘색채와 빛’ 도시를 완성하여 고소천사...   \n",
              "2  전남드래곤즈 임직원과 선수단이 4일 구봉산 정상에 올라 일출을 보며 2018년 구단...   \n",
              "3  광양시는 농업인들의 경쟁력을 높이고, 소득안정을 위해 매실·감·참다래 등 지역특화작...   \n",
              "4  올해 4월과 6월 두 차례에 걸쳐 타이완의 크루즈 관광객 4000여명이 여수에 입항...   \n",
              "\n",
              "                                             CONTENT  \n",
              "0  [전라남도가 쌀 과잉문제를 근본적으로 해결하기 위해 올해부터 시행하는 쌀 생산조정제...  \n",
              "1  [여수시는 원도심 일대에서 추진된 컬러빌리지 사업을 지난해 말 마무리하며 색채와 빛...  \n",
              "2  [전남드래곤즈(사장 신승재)는 지난 4일 구봉산 해맞이 행사를 통해 새해 각오를 다...  \n",
              "3  [광양시는 오는 11일부터 24일까지 농업인교육관과 읍면동 회의실에서 농업인 105...  \n",
              "4  [타이완의 크루즈관광객 4000여명이 올해 두 차례에 걸쳐 여수에 입항한다., 전라...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9042ffc7-f30f-4d97-b0e7-30320f78caf1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TITLE</th>\n",
              "      <th>ABS_SUM</th>\n",
              "      <th>CONTENT</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>논 타작물 재배, 2월 말까지 신청하세요</td>\n",
              "      <td>전라남도가 쌀 과잉문제를 근본적으로 해결하기 위해 올해부터 벼를 심었던 논에 벼 대...</td>\n",
              "      <td>[전라남도가 쌀 과잉문제를 근본적으로 해결하기 위해 올해부터 시행하는 쌀 생산조정제...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>여수시, 컬러빌리지 마무리...‘색채와 빛’도시 완성</td>\n",
              "      <td>여수시는 컬러빌리지 사업에 8억원을 투입하여 ‘색채와 빛’ 도시를 완성하여 고소천사...</td>\n",
              "      <td>[여수시는 원도심 일대에서 추진된 컬러빌리지 사업을 지난해 말 마무리하며 색채와 빛...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>“새해 정기 받고 올해는 반드시 일내자!”</td>\n",
              "      <td>전남드래곤즈 임직원과 선수단이 4일 구봉산 정상에 올라 일출을 보며 2018년 구단...</td>\n",
              "      <td>[전남드래곤즈(사장 신승재)는 지난 4일 구봉산 해맞이 행사를 통해 새해 각오를 다...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>농업인 역량 강화, 새해 실용교육 실시</td>\n",
              "      <td>광양시는 농업인들의 경쟁력을 높이고, 소득안정을 위해 매실·감·참다래 등 지역특화작...</td>\n",
              "      <td>[광양시는 오는 11일부터 24일까지 농업인교육관과 읍면동 회의실에서 농업인 105...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>타이완 크루즈관광객 4천여명‘전남’온다</td>\n",
              "      <td>올해 4월과 6월 두 차례에 걸쳐 타이완의 크루즈 관광객 4000여명이 여수에 입항...</td>\n",
              "      <td>[타이완의 크루즈관광객 4000여명이 올해 두 차례에 걸쳐 여수에 입항한다., 전라...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9042ffc7-f30f-4d97-b0e7-30320f78caf1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9042ffc7-f30f-4d97-b0e7-30320f78caf1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9042ffc7-f30f-4d97-b0e7-30320f78caf1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.loc[611]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C6NJMH93dCcU",
        "outputId": "96ba6744-3e1d-4a0c-cdee-c56db05d9dea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TITLE                              경기불황 불구, 광양지역 기부액 오히려 늘었다\n",
              "ABS_SUM    지난해 전국적인 경기불황으로 곳곳에서 기부금이 줄어들고 있음에도 불구하고 광양지역은...\n",
              "CONTENT                                                   []\n",
              "Name: 611, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 전처리\n"
      ],
      "metadata": {
        "id": "oto4uu3Lo-Si"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 띄어쓰기 및 불용어 처리"
      ],
      "metadata": {
        "id": "OO_YIvWSpn8S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 한국어 불용어 리스트 크롤링\n",
        "\n",
        "\n",
        "url = \"https://www.ranks.nl/stopwords/korean\"\n",
        "response = requests.get(url, verify = False)\n",
        "\n",
        "if response.status_code == 200:\n",
        "    soup = BeautifulSoup(response.text,'html.parser')\n",
        "    content = soup.select_one('#article178ebefbfb1b165454ec9f168f545239 > div.panel-body > table > tbody > tr')\n",
        "    stop_words=[]\n",
        "    for x in content.strings:\n",
        "        x=x.strip()\n",
        "        if x:\n",
        "            stop_words.append(x)\n",
        "    print(f\"# Korean stop words: {len(stop_words)}\")\n",
        "else:\n",
        "    print(response.status_code)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dUNSUY6BpoWA",
        "outputId": "84037202-820d-4792-b194-4fdf3eda02f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py:988: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.ranks.nl'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
            "  InsecureRequestWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# Korean stop words: 677\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "okt = Okt()\n",
        "\n",
        "def title_tokenizing(x):\n",
        "    temp_data = okt.morphs(x)\n",
        "    temp_list = []\n",
        "    for word in temp_data:\n",
        "        if word in stop_words: \n",
        "            continue\n",
        "        temp_list.append(word)\n",
        "  \n",
        "    return \" \".join(temp_list)\n",
        "    \n",
        "    \n",
        "def content_tokenizing(x):\n",
        "    new_list = list(filter(None, x))\n",
        "    \n",
        "    final_list = []\n",
        "    for i in new_list:\n",
        "        temp_data = okt.morphs(i)\n",
        "        temp_list = []\n",
        "        for word in temp_data:\n",
        "            if word in stop_words:\n",
        "                continue\n",
        "            temp_list.append(word)\n",
        "        final_list.append(\" \".join(temp_list))\n",
        "\n",
        "    return final_list"
      ],
      "metadata": {
        "id": "zZNL1QH3pr_L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_tokenized = pd.DataFrame()\n",
        "df_tokenized['TITLE'] = df['TITLE'].progress_apply(lambda x: title_tokenizing(x))\n",
        "df_tokenized['ABS_SUM'] = df['ABS_SUM'].progress_apply(lambda x: title_tokenizing(x))\n",
        "df_tokenized['CONTENT'] = df['CONTENT'].progress_apply(lambda x: content_tokenizing(x))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_4RVkSI4puK1",
        "outputId": "7745339f-bd6d-4fed-faba-c1bc88bb2b90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20000/20000 [02:59<00:00, 111.54it/s]\n",
            "100%|██████████| 20000/20000 [15:27<00:00, 21.56it/s]\n",
            "100%|██████████| 20000/20000 [1:12:33<00:00,  4.59it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "idx_list = []\n",
        "for i in range(len(df_tokenized)):\n",
        "    sentence_list = df_tokenized['CONTENT'].iloc[i]\n",
        "    if len(sentence_list) == 0:\n",
        "        idx_list.append(i)"
      ],
      "metadata": {
        "id": "Ma-vDP8fbYX5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_tokenized = df_tokenized.drop(idx_list)"
      ],
      "metadata": {
        "id": "dbAAnbXpdo--"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(df_tokenized)):\n",
        "    sentence_list = df_tokenized['CONTENT'].iloc[i]\n",
        "    if len(sentence_list) == 0:\n",
        "        print(i)"
      ],
      "metadata": {
        "id": "IFNUVSwKd9QL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Extractive summarization - Matchsum"
      ],
      "metadata": {
        "id": "YG-whFzRpzr_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset & Dataloader 생성"
      ],
      "metadata": {
        "id": "AZNvzp-vp2c6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# input_id 가 들어오면 문장 앞뒤로 cls,sep토큰을 붙여주고 길이에 맞춰 padding을 해준다.\n",
        "# 문장을 여러 개 합친 조합을 하나의 문장으로 처리해야 하기에 따로 함수가 필요하다\n",
        "\n",
        "def control_input_ids(input_ids_tensor,length,cls_token_num,sep_token_num,pad_token_num): \n",
        "  cur_length = len(input_ids_tensor)\n",
        "  cls_token = torch.tensor([cls_token_num])\n",
        "  sep_token = torch.tensor([sep_token_num])\n",
        "\n",
        "  if cur_length+2 > length:\n",
        "    input_ids_tensor = input_ids_tensor[:length-2]  # 길이가 넘치면 자른다\n",
        "    return torch.cat([cls_token,input_ids_tensor,sep_token])\n",
        "  else:\n",
        "    input_ids_tensor = torch.cat([cls_token,input_ids_tensor,sep_token])\n",
        "    padding_list = torch.tensor([pad_token_num]*(length - cur_length -2)) # 길이가 모자라면 padding token 을 채운다\n",
        "    return torch.cat([input_ids_tensor,padding_list])"
      ],
      "metadata": {
        "id": "kqHbB9C6p4W5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def custom_collate_fn(samples):\n",
        "  \n",
        "  text_ids = torch.empty(0,512)\n",
        "  labels_ids = torch.empty(0,32)\n",
        "  for sample in samples:\n",
        "    text_ids = torch.cat([text_ids,sample['text_input_ids'].unsqueeze(0)],dim=0) \n",
        "    labels_ids = torch.cat([labels_ids,sample['labels_input_ids'].unsqueeze(0)],dim=0)\n",
        "\n",
        "  sentence_input_ids = [sample['sentence_input_ids'] for sample in samples]\n",
        "  nn.utils.rnn.pad_sequence(sentence_input_ids,batch_first=True,padding_value = 3)\n",
        "\n",
        "  return dict(text_input_ids = text_ids.to(torch.int64), labels_input_ids = labels_ids.to(torch.int64), sentence_input_ids = sentence_input_ids)"
      ],
      "metadata": {
        "id": "a33us-Wyp6tA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "  def __init__(\n",
        "      self, data, tokenizer,\n",
        "      text_max_token_len = 512,\n",
        "      summary_max_token_len = 32\n",
        "        ):\n",
        "    self.tokenizer = tokenizer\n",
        "    self.data = data\n",
        "    self.text_max_token_len = text_max_token_len\n",
        "    self.summary_max_token_len = summary_max_token_len\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "  \n",
        "  def __getitem__(self, index):\n",
        "    cls_token_num = 0\n",
        "    sep_token_num = 1\n",
        "    pad_token_num = 3\n",
        "    \n",
        "    data_row = self.data.iloc[index]\n",
        "    text = data_row['CONTENT']\n",
        "    \n",
        "    total_text_ids = torch.tensor([])\n",
        "    sentence_input_ids = torch.empty(0,32)\n",
        "\n",
        "    for sentence in text:\n",
        "      text_encoding_sentence = self.tokenizer(\n",
        "          sentence,return_tensors = \"pt\",add_special_tokens=False)\n",
        "      sentence_indiv_input_ids = text_encoding_sentence['input_ids'].flatten()\n",
        "      total_text_ids = torch.cat([total_text_ids,sentence_indiv_input_ids])\n",
        "\n",
        "      sentence_indiv_input_ids = control_input_ids(sentence_indiv_input_ids,self.summary_max_token_len,cls_token_num,sep_token_num,pad_token_num)\n",
        "      sentence_indiv_input_ids = sentence_indiv_input_ids.unsqueeze(0)\n",
        "      sentence_input_ids = torch.cat([sentence_input_ids,sentence_indiv_input_ids],dim=0)\n",
        "    \n",
        "    sentence_input_ids = sentence_input_ids.to(torch.int64)\n",
        "    total_text_ids = control_input_ids(total_text_ids,self.text_max_token_len,cls_token_num,sep_token_num,pad_token_num)    \n",
        "    total_text_ids = total_text_ids\n",
        "\n",
        "    labels = data_row['TITLE']\n",
        "    summary_encoding = self.tokenizer(\n",
        "        labels,\n",
        "        add_special_tokens = False,\n",
        "        return_tensors = \"pt\"\n",
        "    )\n",
        "\n",
        "    labels_ids = summary_encoding['input_ids'].flatten()\n",
        "    labels_ids = control_input_ids(labels_ids,self.summary_max_token_len,cls_token_num,sep_token_num,pad_token_num)\n",
        "\n",
        "    return dict(text_input_ids = total_text_ids, labels_input_ids = labels_ids, sentence_input_ids = sentence_input_ids)"
      ],
      "metadata": {
        "id": "ZpZwVO0cp99z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = get_kobart_tokenizer()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I2cz4lEEqBxJ",
        "outputId": "6ab242bd-63ac-42eb-a3b3-ac07a2bed35a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/.cache/kobart_base_tokenizer_cased_cf74400bce.zip[██████████████████████████████████████████████████]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer.decode(torch.tensor([0])))\n",
        "print(tokenizer.decode(torch.tensor([1])))\n",
        "print(tokenizer.decode(torch.tensor([3])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yAhq8apDZQa5",
        "outputId": "b7efec68-b904-4e85-ed09-f2e7b3390faa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s>\n",
            "</s>\n",
            "<pad>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "whole_dataset = CustomDataset(df_tokenized,tokenizer)\n",
        "\n",
        "train_set_num = len(df_tokenized)*9//10\n",
        "train_dataset , valid_dataset = random_split(whole_dataset, [train_set_num,len(df_tokenized)-train_set_num])\n",
        "train_dataloader = DataLoader(train_dataset, batch_size = 2, shuffle=True,collate_fn = custom_collate_fn)\n",
        "valid_dataloader =  DataLoader(valid_dataset, batch_size = 2, shuffle=False,collate_fn = custom_collate_fn)"
      ],
      "metadata": {
        "id": "jxEm3qajqDJc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "next(iter(train_dataloader))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vpgi__iVqE3B",
        "outputId": "d0814823-85d8-43fd-e005-fe2779245a3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'labels_input_ids': tensor([[    0, 24382, 19867, 15004, 14174, 11471, 11372, 10518, 16016, 14871,\n",
              "          26299, 14468,     1,     3,     3,     3,     3,     3,     3,     3,\n",
              "              3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
              "              3,     3],\n",
              "         [    0, 14188, 14138, 14138, 13676, 14623, 27917, 15004, 14802, 14092,\n",
              "           9879, 18374, 14160,  8996, 18374, 14160, 18374, 14031, 13586, 15579,\n",
              "          18093,     1,     3,     3,     3,     3,     3,     3,     3,     3,\n",
              "              3,     3]]),\n",
              " 'sentence_input_ids': [tensor([[    0, 14468, 14806, 14770, 14174, 11471, 19696, 29326, 14779, 15785,\n",
              "           14871,  1700, 10256, 14777, 16260,  1700, 10256, 15665, 14174, 11471,\n",
              "           14899, 15404, 15082, 17301, 14432, 14068, 19087, 15183, 14871, 14387,\n",
              "            9067,     1],\n",
              "          [    0, 14119, 11207, 16297, 14099,  9807, 11372, 20318, 14338, 16309,\n",
              "           18102, 14702, 14145, 18043, 18102, 14541, 11319, 22554, 15494, 14435,\n",
              "           11382, 11696, 14814, 27898, 14813, 10834, 15004,  1700,  9287, 12332,\n",
              "           14485,     1],\n",
              "          [    0, 14408, 17353, 14137, 14806, 14128, 14174, 11471, 14871, 26299,\n",
              "           14468, 14232, 14166, 19087, 14765, 14174, 11471, 14871, 15118, 14175,\n",
              "           13586, 29822, 17298,  9754, 27334, 14969, 14128, 24382, 19867, 14121,\n",
              "           17328,     1]]),\n",
              "  tensor([[    0, 14519, 14092,  9879, 14078, 16859, 20290,   314, 19259,  9220,\n",
              "           13146, 22135, 14025, 10608, 14990, 14937,     1,     3,     3,     3,\n",
              "               3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
              "               3,     3],\n",
              "          [    0, 15013, 14188, 14138, 29964, 19031, 14434, 15884, 14802, 14138,\n",
              "           14405, 23032, 14460, 14551, 14059, 14043, 15004, 14086, 14551, 22816,\n",
              "           14053, 16871, 14623, 27917, 15281, 15435, 14236, 16076, 15593, 14432,\n",
              "           17546,     1],\n",
              "          [    0, 14188, 14138, 15193, 14884, 14162, 11973, 14338, 14077,  9000,\n",
              "           14162, 11973, 22554, 21472, 15494, 16601, 14725, 16394, 14190, 12024,\n",
              "           17277, 14128, 14499, 14184, 15259, 14802,  1700, 14275, 14043, 15004,\n",
              "           14086,     1],\n",
              "          [    0, 14141, 16667, 20091, 18761, 14802, 14460, 14551, 14059,  1700,\n",
              "           14275, 14092, 18374, 14114, 14331, 14623, 27917, 23600, 21060, 15280,\n",
              "           21729, 17546,     1,     3,     3,     3,     3,     3,     3,     3,\n",
              "               3,     3],\n",
              "          [    0, 15154, 14184, 15453, 14605, 14710, 10479, 14160,  8996, 15004,\n",
              "           14160, 15004, 14031, 13586, 15579, 14121, 14623, 27917, 14576, 14331,\n",
              "           18093, 21729, 17546,     1,     3,     3,     3,     3,     3,     3,\n",
              "               3,     3],\n",
              "          [    0, 14450, 14256, 14802, 14756, 14982, 14281, 18597, 14183, 15554,\n",
              "            9171, 14137, 15004, 19259, 19516, 15004, 14116, 17521, 11372, 14038,\n",
              "           14031, 13586, 15579, 14138, 14405, 23032, 14331, 15453, 15494, 14623,\n",
              "           27917,     1],\n",
              "          [    0, 14802, 14138, 14405, 23032, 15219, 14551, 14061, 11265, 14160,\n",
              "            9049, 14466, 21060, 14121, 17546,     1,     3,     3,     3,     3,\n",
              "               3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
              "               3,     3],\n",
              "          [    0, 24016, 14093, 14680, 27842, 22607,   263,   306, 24327,   306,\n",
              "             305,   300, 17443, 17546,     1,     3,     3,     3,     3,     3,\n",
              "               3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
              "               3,     3]])],\n",
              " 'text_input_ids': tensor([[    0, 14468, 14806,  ...,     3,     3,     3],\n",
              "         [    0, 14519, 14092,  ...,     3,     3,     3]])}"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Matchsum\n",
        "\n",
        "- 평가 metric -> rdass\n",
        "- 기본적으로 모델에 스코어가 높은 5개의 단일 문장을 뽑고 뽑인 문장으로 만들어진 조합 가운데서 스코어가 높은 조합을 golden summary로 선정\n",
        "- loss 는 margin ranking loss 사용"
      ],
      "metadata": {
        "id": "fqYhQQkTqHCz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_score(doc,label,answer):\n",
        "  score_1 = torch.cosine_similarity(doc,answer,dim=0)\n",
        "  score_2 = torch.cosine_similarity(label,answer,dim=0)\n",
        "  return (score_1+score_2)/2"
      ],
      "metadata": {
        "id": "Di5PZycWqINh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_candidate_id(doc_emb,summary_emb,batch_sentence_id, candidate_num, extract_model,device):\n",
        "    cls_token = torch.tensor([0]).to(device)\n",
        "    sep_token = torch.tensor([1]).to(device)\n",
        "    candidate_ids = torch.empty([0,candidate_num,128]).to(device)\n",
        "    \n",
        "    for batch_idx, sentence_id_tensor in enumerate(batch_sentence_id):\n",
        "      sentence_id_tensor = sentence_id_tensor.to(device)\n",
        "      out = extract_model.forward(sentence_id_tensor)  #sentence_id_tensor = [문장 갯수,32개의 토큰]\n",
        "      hidden_states = out['last_hidden_state'][:,0,:] # [문장 갯수,token 갯수 ,768 dim_vec]\n",
        "      score_list= []\n",
        "      \n",
        "      # 각 문장과 정답 라벨의 score를 비교하여 상위 5개의 문장을 선별한다.(방법은 training encoder 모델을 활용한 rdass)  \n",
        "      for i in range(hidden_states.shape[0]): \n",
        "        score = get_score(doc = doc_emb[batch_idx,:], label = summary_emb[batch_idx,:], answer = hidden_states[i,:])\n",
        "        score_list.append((score,i))\n",
        "      \n",
        "      score_list.sort(key = lambda x: x[0],reverse=True)\n",
        "      idx_list = [idx for _,idx in score_list][:5]\n",
        "    \n",
        "      # 선정된 5개의 문장들로 조합을 한다.\n",
        "      # 뽑힌 조합 문장을 연결하고 하나의 문장으로 만들어 다시 score를 측정한다.\n",
        "      # 문서의 문장이 적어 candidate_num보다 조합갯수가 적을 경우 조합을 반복하여 갯수를 맞춘다.\n",
        "      indices = list(combinations(idx_list, 2))\n",
        "      indices += list(combinations(idx_list, 3))\n",
        "      \n",
        "      if len(indices) < 2:\n",
        "        indices = [idx_list]\n",
        "      \n",
        "      len_indices = len(indices) \n",
        "      if len_indices < candidate_num : \n",
        "        indices = indices*(candidate_num//len_indices)\n",
        "        indices.append(idx_list[:-(candidate_num%len_indices)])\n",
        "\n",
        "      # 각 조합 문장과 score를 tuple로 묶고 score 기준으로 내림차순한다.\n",
        "      score = []\n",
        "      for i in indices:\n",
        "          i = list(i)\n",
        "          i.sort()\n",
        "          # write dec\n",
        "          dec = torch.tensor([]).to(device)\n",
        "          for j in i:\n",
        "              sent = sentence_id_tensor[j]\n",
        "              sent = sent[1:]\n",
        "              sep_token_idx = 0\n",
        "              for token_idx in range(len(sent)):\n",
        "                if sent[token_idx] == 2: break\n",
        "                else:sep_token_idx += 1\n",
        "              sent = sent[:sep_token_idx]\n",
        "              dec = torch.cat([dec,sent],dim=0)\n",
        "          \n",
        "          dec = torch.cat([cls_token,dec,sep_token],dim=0)\n",
        "          dec = dec.to(torch.int64)\n",
        "          dec_out = extract_model.forward(input_ids = dec.unsqueeze(0))\n",
        "          score.append((dec, get_score(doc_emb[batch_idx,:],summary_emb[batch_idx,:], dec_out['last_hidden_state'][0,0,:])))\n",
        "      \n",
        "      score.sort(key=lambda x : x[1], reverse=True)\n",
        "      score = score[:candidate_num]\n",
        "      \n",
        "      candidate_ids_ind= torch.empty(0,128).to(device)\n",
        "      for k,_ in score:\n",
        "        dec = k\n",
        "        if len(dec) < 128:\n",
        "          padding_list = torch.tensor([3]*(128-len(dec))).to(device)\n",
        "          dec = torch.cat([k,padding_list],dim=0)\n",
        "        else:\n",
        "          dec = dec[:128]\n",
        "\n",
        "        candidate_ids_ind = torch.cat([candidate_ids_ind,dec.unsqueeze(0)],dim = 0)\n",
        "\n",
        "      candidate_ids = torch.cat([candidate_ids,candidate_ids_ind.unsqueeze(0)],dim = 0)\n",
        "\n",
        "    return candidate_ids.to(torch.int64)"
      ],
      "metadata": {
        "id": "8l_xpj1ZqLfo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MatchSum(nn.Module):  \n",
        "    def __init__ (self, encoder, candidate_num, device,hidden_size=768):\n",
        "        super(MatchSum, self).__init__()\n",
        "        \n",
        "        self.hidden_size = hidden_size\n",
        "        self.candidate_num  = candidate_num\n",
        "        self.encoder = encoder\n",
        "        self.device = device\n",
        "\n",
        "    def forward(self, text_id, summary_id,list_of_sentence_id):\n",
        "        \n",
        "        batch_size = text_id.size(0)\n",
        "        pad_id = 3\n",
        "\n",
        "        # get document embedding\n",
        "        input_mask = ~(text_id == pad_id)\n",
        "        out = self.encoder(text_id, attention_mask=input_mask)['last_hidden_state'] # last layer\n",
        "        doc_emb = out[:, 0, :]\n",
        "        assert doc_emb.size() == (batch_size, self.hidden_size) # [batch_size, hidden_size]\n",
        "        \n",
        "        # get summary embedding\n",
        "        input_mask = ~(summary_id == pad_id)\n",
        "        out = self.encoder(summary_id, attention_mask=input_mask)['last_hidden_state'] # last layer\n",
        "        summary_emb = out[:, 0, :]\n",
        "        assert summary_emb.size() == (batch_size, self.hidden_size) # [batch_size, hidden_size]\n",
        "\n",
        "        # get summary score\n",
        "        summary_score = torch.cosine_similarity(summary_emb, doc_emb, dim=-1)\n",
        "\n",
        "        # get candidate embedding\n",
        "        candidate_id = get_candidate_id(doc_emb,summary_emb,list_of_sentence_id, self.candidate_num, self.encoder,self.device) #[batch_size , candidate_num, token_num]\n",
        "        candidate_id_copy = candidate_id\n",
        "        candidate_id = candidate_id.view(-1, candidate_id.size(-1)) \n",
        "        input_mask = ~(candidate_id == pad_id)\n",
        "        out = self.encoder(candidate_id, attention_mask=input_mask)['last_hidden_state'] \n",
        "        candidate_emb = out[:, 0, :].view(batch_size, self.candidate_num, self.hidden_size)  # [batch_size, candidate_num, hidden_size]\n",
        "        assert candidate_emb.size() == (batch_size, self.candidate_num, self.hidden_size)\n",
        "        \n",
        "        # get candidate score\n",
        "        doc_emb = doc_emb.unsqueeze(1).expand_as(candidate_emb)\n",
        "        score = torch.cosine_similarity(candidate_emb, doc_emb, dim=-1) # [batch_size, candidate_num]\n",
        "        golden_list = torch.argmax(score,dim=1)\n",
        "        assert score.size() == (batch_size, self.candidate_num)\n",
        "\n",
        "        candidate_id = candidate_id.view(-1, candidate_id.size(-1)) \n",
        "\n",
        "        return {'score': score, 'summary_score': summary_score,  'golden_summary':candidate_id_copy[:,0,:]}"
      ],
      "metadata": {
        "id": "PLhoh4nOqOL0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MarginRankingLoss():      \n",
        "    \n",
        "    def __init__(self, margin, score=None, summary_score=None):\n",
        "        super(MarginRankingLoss, self).__init__()\n",
        "        # self._init_param_map(score=score, summary_score=summary_score)\n",
        "        self.margin = margin\n",
        "        self.loss_func = torch.nn.MarginRankingLoss(margin)\n",
        "\n",
        "    def get_loss(self, score, summary_score):\n",
        "        \n",
        "        # equivalent to initializing TotalLoss to 0\n",
        "        # here is to avoid that some special samples will not go into the following for loop\n",
        "        ones = torch.ones(score.size()).cuda(score.device)\n",
        "        loss_func = torch.nn.MarginRankingLoss(0.0)\n",
        "        TotalLoss = loss_func(score, score, ones)\n",
        "\n",
        "        # candidate loss\n",
        "        n = score.size(1)\n",
        "        for i in range(1, n):\n",
        "            pos_score = score[:, :-i]\n",
        "            neg_score = score[:, i:]\n",
        "            pos_score = pos_score.contiguous().view(-1)\n",
        "            neg_score = neg_score.contiguous().view(-1)\n",
        "            ones = torch.ones(pos_score.size()).cuda(score.device)\n",
        "            loss_func = torch.nn.MarginRankingLoss(self.margin * i)\n",
        "            TotalLoss += loss_func(pos_score, neg_score, ones)\n",
        "\n",
        "        # gold summary loss\n",
        "        pos_score = summary_score.unsqueeze(-1).expand_as(score)\n",
        "        neg_score = score\n",
        "        pos_score = pos_score.contiguous().view(-1)\n",
        "        neg_score = neg_score.contiguous().view(-1)\n",
        "        ones = torch.ones(pos_score.size()).cuda(score.device)\n",
        "        loss_func = torch.nn.MarginRankingLoss(0.0)\n",
        "        TotalLoss += loss_func(pos_score, neg_score, ones)\n",
        "        \n",
        "        return TotalLoss"
      ],
      "metadata": {
        "id": "01l-gvQKqPtR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train code\n",
        "\n",
        "- Encoder -> KoBART\n",
        "- GLM 을 제외한 제일 성능 좋은 모델이고 한국어로 train이 되어 있어 선정함"
      ],
      "metadata": {
        "id": "4FaEz7fxqRPA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = BartModel.from_pretrained(get_pytorch_kobart_model())\n",
        "summary_model = MatchSum(encoder = model, candidate_num = 5,device = device, hidden_size=768) \n",
        "\n",
        "N_EPOCHS = 3\n",
        "optimizer = AdamW(model.parameters(),lr =5e-5)\n",
        "scheduler = CosineAnnealingLR(optimizer,T_max = len(train_dataloader)*2)\n",
        "criterion = MarginRankingLoss(margin = 0.01)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l760jJIZsikh",
        "outputId": "dda5e93f-92bd-4933-f986-a678fc3a858e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/.cache/kobart_base_cased_ff4bda5738.zip[██████████████████████████████████████████████████]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.to(device)\n",
        "summary_model.to(device)\n",
        "wandb.init(project='summarization', entity='tkdlqh2')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    \n",
        "    print(f\"*****Epoch {epoch} Train Start*****\")\n",
        "    print(f\"*****Epoch {epoch} Total Step {len(train_dataloader)}*****\")\n",
        "    total_loss, batch_loss, batch_step = 0,0,0\n",
        "    model.train()\n",
        "\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        batch_step+=1\n",
        "        text_input_ids = batch[\"text_input_ids\"].to(device)        \n",
        "        label_input_ids = batch[\"labels_input_ids\"].to(device)\n",
        "\n",
        "        model.zero_grad()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward\n",
        "        output = summary_model.forward(text_input_ids, label_input_ids,batch[\"sentence_input_ids\"])\n",
        "        loss = criterion.get_loss(score = output[\"score\"],summary_score = output[\"summary_score\"])\n",
        "\n",
        "        # loss 계산\n",
        "        loss.backward()\n",
        "        # optimizer 업데이트\n",
        "        optimizer.step()\n",
        "        # scheduler 업데이트\n",
        "        scheduler.step()\n",
        "\n",
        "        batch_loss += loss.item()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        learning_rate = optimizer.param_groups[0]['lr']\n",
        "        wandb.log({'train/lr':learning_rate,\"train/loss\":loss.item()})\n",
        "\n",
        "        if (step%50 == 0) and (step!=0):\n",
        "            print(f\"Step: {step} Loss: {batch_loss/batch_step:.4f} lr: {optimizer.param_groups[0]['lr']:.4f}\")\n",
        "            # 변수 초기화    \n",
        "            batch_loss, batch_step = 0,0\n",
        "\n",
        "    print(f\"Epoch {epoch} Total Mean Loss : {total_loss/(step+1):.4f}\")\n",
        "    \n",
        "    with torch.no_grad():\n",
        "      print('**Calculating validation results...**')\n",
        "      total_val_loss,batch_step = 0,0\n",
        "      model.eval()\n",
        "      for step, batch in enumerate(valid_dataloader):\n",
        "          batch_step+=1\n",
        "          text_input_ids = batch[\"text_input_ids\"].to(device)        \n",
        "          label_input_ids = batch[\"labels_input_ids\"].to(device)\n",
        "\n",
        "          # forward\n",
        "          output = summary_model.forward(text_input_ids, label_input_ids,batch[\"sentence_input_ids\"])\n",
        "          val_loss = criterion.get_loss(score = output[\"score\"],summary_score = output[\"summary_score\"])\n",
        "\n",
        "          total_val_loss += val_loss.item()\n",
        "          wandb.log({\"val/loss\":val_loss.item()})\n",
        "\n",
        "    print(f\"Epoch {epoch} Total Mean Score : {total_val_loss/(step+1):.4f}\")\n",
        "    \n",
        "    print(f\"*****Epoch {epoch} Train Finished*****\\n\")\n",
        "    torch.save(model.state_dict(),f\"/content/drive/MyDrive/Summary_task/kobart_model_{epoch}epoch.pth\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "kXngEWOXsj2g",
        "outputId": "a8ccd6a2-fffb-4f4f-a97b-eed44da93edd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.12.14"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20220412_173207-3sw4qpqp</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/tkdlqh2/summarization/runs/3sw4qpqp\" target=\"_blank\">sage-forest-14</a></strong> to <a href=\"https://wandb.ai/tkdlqh2/summarization\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*****Epoch 0 Train Start*****\n",
            "*****Epoch 0 Total Step 8990*****\n",
            "Step: 50 Loss: 0.1260 lr: 0.0000\n",
            "Step: 100 Loss: 0.0917 lr: 0.0000\n",
            "Step: 150 Loss: 0.0936 lr: 0.0000\n",
            "Step: 200 Loss: 0.0821 lr: 0.0000\n",
            "Step: 250 Loss: 0.0772 lr: 0.0000\n",
            "Step: 300 Loss: 0.0848 lr: 0.0000\n",
            "Step: 350 Loss: 0.0662 lr: 0.0000\n",
            "Step: 400 Loss: 0.0841 lr: 0.0000\n",
            "Step: 450 Loss: 0.0764 lr: 0.0000\n",
            "Step: 500 Loss: 0.0517 lr: 0.0000\n",
            "Step: 550 Loss: 0.0749 lr: 0.0000\n",
            "Step: 600 Loss: 0.0640 lr: 0.0000\n",
            "Step: 650 Loss: 0.0532 lr: 0.0000\n",
            "Step: 700 Loss: 0.0635 lr: 0.0000\n",
            "Step: 750 Loss: 0.0652 lr: 0.0000\n",
            "Step: 800 Loss: 0.0490 lr: 0.0000\n",
            "Step: 850 Loss: 0.0448 lr: 0.0000\n",
            "Step: 900 Loss: 0.0456 lr: 0.0000\n",
            "Step: 950 Loss: 0.0481 lr: 0.0000\n",
            "Step: 1000 Loss: 0.0544 lr: 0.0000\n",
            "Step: 1050 Loss: 0.0611 lr: 0.0000\n",
            "Step: 1100 Loss: 0.0436 lr: 0.0000\n",
            "Step: 1150 Loss: 0.0434 lr: 0.0000\n",
            "Step: 1200 Loss: 0.0482 lr: 0.0000\n",
            "Step: 1250 Loss: 0.0397 lr: 0.0000\n",
            "Step: 1300 Loss: 0.0465 lr: 0.0000\n",
            "Step: 1350 Loss: 0.0488 lr: 0.0000\n",
            "Step: 1400 Loss: 0.0515 lr: 0.0000\n",
            "Step: 1450 Loss: 0.0473 lr: 0.0000\n",
            "Step: 1500 Loss: 0.0395 lr: 0.0000\n",
            "Step: 1550 Loss: 0.0537 lr: 0.0000\n",
            "Step: 1600 Loss: 0.0422 lr: 0.0000\n",
            "Step: 1650 Loss: 0.0385 lr: 0.0000\n",
            "Step: 1700 Loss: 0.0338 lr: 0.0000\n",
            "Step: 1750 Loss: 0.0402 lr: 0.0000\n",
            "Step: 1800 Loss: 0.0383 lr: 0.0000\n",
            "Step: 1850 Loss: 0.0333 lr: 0.0000\n",
            "Step: 1900 Loss: 0.0361 lr: 0.0000\n",
            "Step: 1950 Loss: 0.0377 lr: 0.0000\n",
            "Step: 2000 Loss: 0.0322 lr: 0.0000\n",
            "Step: 2050 Loss: 0.0321 lr: 0.0000\n",
            "Step: 2100 Loss: 0.0378 lr: 0.0000\n",
            "Step: 2150 Loss: 0.0368 lr: 0.0000\n",
            "Step: 2200 Loss: 0.0389 lr: 0.0000\n",
            "Step: 2250 Loss: 0.0274 lr: 0.0000\n",
            "Step: 2300 Loss: 0.0294 lr: 0.0000\n",
            "Step: 2350 Loss: 0.0316 lr: 0.0000\n",
            "Step: 2400 Loss: 0.0282 lr: 0.0000\n",
            "Step: 2450 Loss: 0.0300 lr: 0.0000\n",
            "Step: 2500 Loss: 0.0218 lr: 0.0000\n",
            "Step: 2550 Loss: 0.0213 lr: 0.0000\n",
            "Step: 2600 Loss: 0.0278 lr: 0.0000\n",
            "Step: 2650 Loss: 0.0236 lr: 0.0000\n",
            "Step: 2700 Loss: 0.0279 lr: 0.0000\n",
            "Step: 2750 Loss: 0.0310 lr: 0.0000\n",
            "Step: 2800 Loss: 0.0248 lr: 0.0000\n",
            "Step: 2850 Loss: 0.0206 lr: 0.0000\n",
            "Step: 2900 Loss: 0.0275 lr: 0.0000\n",
            "Step: 2950 Loss: 0.0222 lr: 0.0000\n",
            "Step: 3000 Loss: 0.0277 lr: 0.0000\n",
            "Step: 3050 Loss: 0.0235 lr: 0.0000\n",
            "Step: 3100 Loss: 0.0202 lr: 0.0000\n",
            "Step: 3150 Loss: 0.0173 lr: 0.0000\n",
            "Step: 3200 Loss: 0.0343 lr: 0.0000\n",
            "Step: 3250 Loss: 0.0436 lr: 0.0000\n",
            "Step: 3300 Loss: 0.0326 lr: 0.0000\n",
            "Step: 3350 Loss: 0.0318 lr: 0.0000\n",
            "Step: 3400 Loss: 0.0282 lr: 0.0000\n",
            "Step: 3450 Loss: 0.0264 lr: 0.0000\n",
            "Step: 3500 Loss: 0.0299 lr: 0.0000\n",
            "Step: 3550 Loss: 0.0203 lr: 0.0000\n",
            "Step: 3600 Loss: 0.0274 lr: 0.0000\n",
            "Step: 3650 Loss: 0.0275 lr: 0.0000\n",
            "Step: 3700 Loss: 0.0263 lr: 0.0000\n",
            "Step: 3750 Loss: 0.0227 lr: 0.0000\n",
            "Step: 3800 Loss: 0.0280 lr: 0.0000\n",
            "Step: 3850 Loss: 0.0193 lr: 0.0000\n",
            "Step: 3900 Loss: 0.0209 lr: 0.0000\n",
            "Step: 3950 Loss: 0.0224 lr: 0.0000\n",
            "Step: 4000 Loss: 0.0262 lr: 0.0000\n",
            "Step: 4050 Loss: 0.0208 lr: 0.0000\n",
            "Step: 4100 Loss: 0.0139 lr: 0.0000\n",
            "Step: 4150 Loss: 0.0217 lr: 0.0000\n",
            "Step: 4200 Loss: 0.0190 lr: 0.0000\n",
            "Step: 4250 Loss: 0.0196 lr: 0.0000\n",
            "Step: 4300 Loss: 0.0145 lr: 0.0000\n",
            "Step: 4350 Loss: 0.0213 lr: 0.0000\n",
            "Step: 4400 Loss: 0.0276 lr: 0.0000\n",
            "Step: 4450 Loss: 0.0290 lr: 0.0000\n",
            "Step: 4500 Loss: 0.0279 lr: 0.0000\n",
            "Step: 4550 Loss: 0.0206 lr: 0.0000\n",
            "Step: 4600 Loss: 0.0138 lr: 0.0000\n",
            "Step: 4650 Loss: 0.0219 lr: 0.0000\n",
            "Step: 4700 Loss: 0.0234 lr: 0.0000\n",
            "Step: 4750 Loss: 0.0238 lr: 0.0000\n",
            "Step: 4800 Loss: 0.0201 lr: 0.0000\n",
            "Step: 4850 Loss: 0.0198 lr: 0.0000\n",
            "Step: 4900 Loss: 0.0178 lr: 0.0000\n",
            "Step: 4950 Loss: 0.0185 lr: 0.0000\n",
            "Step: 5000 Loss: 0.0234 lr: 0.0000\n",
            "Step: 5050 Loss: 0.0264 lr: 0.0000\n",
            "Step: 5100 Loss: 0.0228 lr: 0.0000\n",
            "Step: 5150 Loss: 0.0215 lr: 0.0000\n",
            "Step: 5200 Loss: 0.0209 lr: 0.0000\n",
            "Step: 5250 Loss: 0.0212 lr: 0.0000\n",
            "Step: 5300 Loss: 0.0187 lr: 0.0000\n",
            "Step: 5350 Loss: 0.0413 lr: 0.0000\n",
            "Step: 5400 Loss: 0.0267 lr: 0.0000\n",
            "Step: 5450 Loss: 0.0365 lr: 0.0000\n",
            "Step: 5500 Loss: 0.0353 lr: 0.0000\n",
            "Step: 5550 Loss: 0.0298 lr: 0.0000\n",
            "Step: 5600 Loss: 0.0409 lr: 0.0000\n",
            "Step: 5650 Loss: 0.0308 lr: 0.0000\n",
            "Step: 5700 Loss: 0.0254 lr: 0.0000\n",
            "Step: 5750 Loss: 0.0318 lr: 0.0000\n",
            "Step: 5800 Loss: 0.0310 lr: 0.0000\n",
            "Step: 5850 Loss: 0.0243 lr: 0.0000\n",
            "Step: 5900 Loss: 0.0309 lr: 0.0000\n",
            "Step: 5950 Loss: 0.0193 lr: 0.0000\n",
            "Step: 6000 Loss: 0.0184 lr: 0.0000\n",
            "Step: 6050 Loss: 0.0218 lr: 0.0000\n",
            "Step: 6100 Loss: 0.0180 lr: 0.0000\n",
            "Step: 6150 Loss: 0.0184 lr: 0.0000\n",
            "Step: 6200 Loss: 0.0190 lr: 0.0000\n",
            "Step: 6250 Loss: 0.0227 lr: 0.0000\n",
            "Step: 6300 Loss: 0.0241 lr: 0.0000\n",
            "Step: 6350 Loss: 0.0308 lr: 0.0000\n",
            "Step: 6400 Loss: 0.0338 lr: 0.0000\n",
            "Step: 6450 Loss: 0.0829 lr: 0.0000\n",
            "Step: 6500 Loss: 0.0831 lr: 0.0000\n",
            "Step: 6550 Loss: 0.0874 lr: 0.0000\n",
            "Step: 6600 Loss: 0.0823 lr: 0.0000\n",
            "Step: 6650 Loss: 0.0828 lr: 0.0000\n",
            "Step: 6700 Loss: 0.0784 lr: 0.0000\n",
            "Step: 6750 Loss: 0.0749 lr: 0.0000\n",
            "Step: 6800 Loss: 0.0716 lr: 0.0000\n",
            "Step: 6850 Loss: 0.0584 lr: 0.0000\n",
            "Step: 6900 Loss: 0.0450 lr: 0.0000\n",
            "Step: 6950 Loss: 0.0428 lr: 0.0000\n",
            "Step: 7000 Loss: 0.0341 lr: 0.0000\n",
            "Step: 7050 Loss: 0.0386 lr: 0.0000\n",
            "Step: 7100 Loss: 0.0364 lr: 0.0000\n",
            "Step: 7150 Loss: 0.0436 lr: 0.0000\n",
            "Step: 7200 Loss: 0.0331 lr: 0.0000\n",
            "Step: 7250 Loss: 0.0330 lr: 0.0000\n",
            "Step: 7300 Loss: 0.0352 lr: 0.0000\n",
            "Step: 7350 Loss: 0.0338 lr: 0.0000\n",
            "Step: 7400 Loss: 0.0271 lr: 0.0000\n",
            "Step: 7450 Loss: 0.0327 lr: 0.0000\n",
            "Step: 7500 Loss: 0.0325 lr: 0.0000\n",
            "Step: 7550 Loss: 0.0372 lr: 0.0000\n",
            "Step: 7600 Loss: 0.0286 lr: 0.0000\n",
            "Step: 7650 Loss: 0.0287 lr: 0.0000\n",
            "Step: 7700 Loss: 0.0347 lr: 0.0000\n",
            "Step: 7750 Loss: 0.0250 lr: 0.0000\n",
            "Step: 7800 Loss: 0.0237 lr: 0.0000\n",
            "Step: 7850 Loss: 0.0220 lr: 0.0000\n",
            "Step: 7900 Loss: 0.0241 lr: 0.0000\n",
            "Step: 7950 Loss: 0.0276 lr: 0.0000\n",
            "Step: 8000 Loss: 0.0226 lr: 0.0000\n",
            "Step: 8050 Loss: 0.0211 lr: 0.0000\n",
            "Step: 8100 Loss: 0.0190 lr: 0.0000\n",
            "Step: 8150 Loss: 0.0249 lr: 0.0000\n",
            "Step: 8200 Loss: 0.0244 lr: 0.0000\n",
            "Step: 8250 Loss: 0.0277 lr: 0.0000\n",
            "Step: 8300 Loss: 0.0260 lr: 0.0000\n",
            "Step: 8350 Loss: 0.0324 lr: 0.0000\n",
            "Step: 8400 Loss: 0.0282 lr: 0.0000\n",
            "Step: 8450 Loss: 0.0311 lr: 0.0000\n",
            "Step: 8500 Loss: 0.0306 lr: 0.0000\n",
            "Step: 8550 Loss: 0.0278 lr: 0.0000\n",
            "Step: 8600 Loss: 0.0309 lr: 0.0000\n",
            "Step: 8650 Loss: 0.0366 lr: 0.0000\n",
            "Step: 8700 Loss: 0.0311 lr: 0.0000\n",
            "Step: 8750 Loss: 0.0358 lr: 0.0000\n",
            "Step: 8800 Loss: 0.0344 lr: 0.0000\n",
            "Step: 8850 Loss: 0.0260 lr: 0.0000\n",
            "Step: 8900 Loss: 0.0210 lr: 0.0000\n",
            "Step: 8950 Loss: 0.0240 lr: 0.0000\n",
            "Epoch 0 Total Mean Loss : 0.0362\n",
            "**Calculating validation results...**\n",
            "Epoch 0 Total Mean Score : 0.0106\n",
            "*****Epoch 0 Train Finished*****\n",
            "\n",
            "*****Epoch 1 Train Start*****\n",
            "*****Epoch 1 Total Step 8990*****\n",
            "Step: 50 Loss: 0.0232 lr: 0.0000\n",
            "Step: 100 Loss: 0.0196 lr: 0.0000\n",
            "Step: 150 Loss: 0.0222 lr: 0.0000\n",
            "Step: 200 Loss: 0.0207 lr: 0.0000\n",
            "Step: 250 Loss: 0.0248 lr: 0.0000\n",
            "Step: 300 Loss: 0.0203 lr: 0.0000\n",
            "Step: 350 Loss: 0.0198 lr: 0.0000\n",
            "Step: 400 Loss: 0.0198 lr: 0.0000\n",
            "Step: 450 Loss: 0.0266 lr: 0.0000\n",
            "Step: 500 Loss: 0.0204 lr: 0.0000\n",
            "Step: 550 Loss: 0.0223 lr: 0.0000\n",
            "Step: 600 Loss: 0.0219 lr: 0.0000\n",
            "Step: 650 Loss: 0.0207 lr: 0.0000\n",
            "Step: 700 Loss: 0.0235 lr: 0.0000\n",
            "Step: 750 Loss: 0.0239 lr: 0.0000\n",
            "Step: 800 Loss: 0.0195 lr: 0.0000\n",
            "Step: 850 Loss: 0.0209 lr: 0.0000\n",
            "Step: 900 Loss: 0.0232 lr: 0.0000\n",
            "Step: 950 Loss: 0.0225 lr: 0.0000\n",
            "Step: 1000 Loss: 0.0269 lr: 0.0000\n",
            "Step: 1050 Loss: 0.0183 lr: 0.0000\n",
            "Step: 1100 Loss: 0.0175 lr: 0.0000\n",
            "Step: 1150 Loss: 0.0193 lr: 0.0000\n",
            "Step: 1200 Loss: 0.0199 lr: 0.0000\n",
            "Step: 1250 Loss: 0.0165 lr: 0.0000\n",
            "Step: 1300 Loss: 0.0233 lr: 0.0000\n",
            "Step: 1350 Loss: 0.0410 lr: 0.0000\n",
            "Step: 1400 Loss: 0.0318 lr: 0.0000\n",
            "Step: 1450 Loss: 0.0342 lr: 0.0000\n",
            "Step: 1500 Loss: 0.0369 lr: 0.0000\n",
            "Step: 1550 Loss: 0.0334 lr: 0.0000\n",
            "Step: 1600 Loss: 0.0351 lr: 0.0000\n",
            "Step: 1650 Loss: 0.0282 lr: 0.0000\n",
            "Step: 1700 Loss: 0.0358 lr: 0.0000\n",
            "Step: 1750 Loss: 0.0259 lr: 0.0000\n",
            "Step: 1800 Loss: 0.0288 lr: 0.0000\n",
            "Step: 1850 Loss: 0.0356 lr: 0.0000\n",
            "Step: 1900 Loss: 0.0459 lr: 0.0000\n",
            "Step: 1950 Loss: 0.0467 lr: 0.0000\n",
            "Step: 2000 Loss: 0.0481 lr: 0.0000\n",
            "Step: 2050 Loss: 0.0599 lr: 0.0000\n",
            "Step: 2100 Loss: 0.0509 lr: 0.0000\n",
            "Step: 2150 Loss: 0.0456 lr: 0.0000\n",
            "Step: 2200 Loss: 0.0434 lr: 0.0000\n",
            "Step: 2250 Loss: 0.0436 lr: 0.0000\n",
            "Step: 2300 Loss: 0.0507 lr: 0.0000\n",
            "Step: 2350 Loss: 0.0412 lr: 0.0000\n",
            "Step: 2400 Loss: 0.0388 lr: 0.0000\n",
            "Step: 2450 Loss: 0.0388 lr: 0.0000\n",
            "Step: 2500 Loss: 0.0379 lr: 0.0000\n",
            "Step: 2550 Loss: 0.0281 lr: 0.0000\n",
            "Step: 2600 Loss: 0.0430 lr: 0.0000\n",
            "Step: 2650 Loss: 0.0325 lr: 0.0000\n",
            "Step: 2700 Loss: 0.0273 lr: 0.0000\n",
            "Step: 2750 Loss: 0.0195 lr: 0.0000\n",
            "Step: 2800 Loss: 0.0294 lr: 0.0000\n",
            "Step: 2850 Loss: 0.0233 lr: 0.0000\n",
            "Step: 2900 Loss: 0.0270 lr: 0.0000\n",
            "Step: 2950 Loss: 0.0268 lr: 0.0000\n",
            "Step: 3000 Loss: 0.0213 lr: 0.0000\n",
            "Step: 3050 Loss: 0.0202 lr: 0.0000\n",
            "Step: 3100 Loss: 0.0199 lr: 0.0000\n",
            "Step: 3150 Loss: 0.0220 lr: 0.0000\n",
            "Step: 3200 Loss: 0.0203 lr: 0.0000\n",
            "Step: 3250 Loss: 0.0151 lr: 0.0000\n",
            "Step: 3300 Loss: 0.0207 lr: 0.0000\n",
            "Step: 3350 Loss: 0.0204 lr: 0.0000\n",
            "Step: 3400 Loss: 0.0221 lr: 0.0000\n",
            "Step: 3450 Loss: 0.0238 lr: 0.0000\n",
            "Step: 3500 Loss: 0.0297 lr: 0.0000\n",
            "Step: 3550 Loss: 0.0262 lr: 0.0000\n",
            "Step: 3600 Loss: 0.0192 lr: 0.0000\n",
            "Step: 3650 Loss: 0.0201 lr: 0.0000\n",
            "Step: 3700 Loss: 0.0252 lr: 0.0000\n",
            "Step: 3750 Loss: 0.0216 lr: 0.0000\n",
            "Step: 3800 Loss: 0.0219 lr: 0.0000\n",
            "Step: 3850 Loss: 0.0209 lr: 0.0000\n",
            "Step: 3900 Loss: 0.0244 lr: 0.0000\n",
            "Step: 3950 Loss: 0.0158 lr: 0.0000\n",
            "Step: 4000 Loss: 0.0121 lr: 0.0000\n",
            "Step: 4050 Loss: 0.0175 lr: 0.0000\n",
            "Step: 4100 Loss: 0.0177 lr: 0.0000\n",
            "Step: 4150 Loss: 0.0227 lr: 0.0000\n",
            "Step: 4200 Loss: 0.0194 lr: 0.0000\n",
            "Step: 4250 Loss: 0.0184 lr: 0.0000\n",
            "Step: 4300 Loss: 0.0192 lr: 0.0000\n",
            "Step: 4350 Loss: 0.0255 lr: 0.0000\n",
            "Step: 4400 Loss: 0.0157 lr: 0.0000\n",
            "Step: 4450 Loss: 0.0197 lr: 0.0000\n",
            "Step: 4500 Loss: 0.0159 lr: 0.0000\n",
            "Step: 4550 Loss: 0.0125 lr: 0.0000\n",
            "Step: 4600 Loss: 0.0164 lr: 0.0000\n",
            "Step: 4650 Loss: 0.0194 lr: 0.0000\n",
            "Step: 4700 Loss: 0.0149 lr: 0.0000\n",
            "Step: 4750 Loss: 0.0158 lr: 0.0000\n",
            "Step: 4800 Loss: 0.0166 lr: 0.0000\n",
            "Step: 4850 Loss: 0.0152 lr: 0.0000\n",
            "Step: 4900 Loss: 0.0126 lr: 0.0000\n",
            "Step: 4950 Loss: 0.0177 lr: 0.0000\n",
            "Step: 5000 Loss: 0.0141 lr: 0.0000\n",
            "Step: 5050 Loss: 0.0187 lr: 0.0000\n",
            "Step: 5100 Loss: 0.0445 lr: 0.0000\n",
            "Step: 5150 Loss: 0.0141 lr: 0.0000\n",
            "Step: 5200 Loss: 0.0165 lr: 0.0000\n",
            "Step: 5250 Loss: 0.0158 lr: 0.0000\n",
            "Step: 5300 Loss: 0.0141 lr: 0.0000\n",
            "Step: 5350 Loss: 0.0116 lr: 0.0000\n",
            "Step: 5400 Loss: 0.0144 lr: 0.0000\n",
            "Step: 5450 Loss: 0.0192 lr: 0.0000\n",
            "Step: 5500 Loss: 0.0173 lr: 0.0000\n",
            "Step: 5550 Loss: 0.0194 lr: 0.0000\n",
            "Step: 5600 Loss: 0.0164 lr: 0.0000\n",
            "Step: 5650 Loss: 0.0173 lr: 0.0000\n",
            "Step: 5700 Loss: 0.0166 lr: 0.0000\n",
            "Step: 5750 Loss: 0.0145 lr: 0.0000\n",
            "Step: 5800 Loss: 0.0136 lr: 0.0000\n",
            "Step: 5850 Loss: 0.0144 lr: 0.0000\n",
            "Step: 5900 Loss: 0.0123 lr: 0.0000\n",
            "Step: 5950 Loss: 0.0148 lr: 0.0000\n",
            "Step: 6000 Loss: 0.0163 lr: 0.0000\n",
            "Step: 6050 Loss: 0.0126 lr: 0.0000\n",
            "Step: 6100 Loss: 0.0178 lr: 0.0000\n",
            "Step: 6150 Loss: 0.0195 lr: 0.0000\n",
            "Step: 6200 Loss: 0.0190 lr: 0.0000\n",
            "Step: 6250 Loss: 0.0178 lr: 0.0000\n",
            "Step: 6300 Loss: 0.0162 lr: 0.0000\n",
            "Step: 6350 Loss: 0.0147 lr: 0.0000\n",
            "Step: 6400 Loss: 0.0183 lr: 0.0000\n",
            "Step: 6450 Loss: 0.0394 lr: 0.0000\n",
            "Step: 6500 Loss: 0.0120 lr: 0.0000\n",
            "Step: 6550 Loss: 0.0157 lr: 0.0000\n",
            "Step: 6600 Loss: 0.0159 lr: 0.0000\n",
            "Step: 6650 Loss: 0.0163 lr: 0.0000\n",
            "Step: 6700 Loss: 0.0206 lr: 0.0000\n",
            "Step: 6750 Loss: 0.0146 lr: 0.0000\n",
            "Step: 6800 Loss: 0.0200 lr: 0.0000\n",
            "Step: 6850 Loss: 0.0151 lr: 0.0000\n",
            "Step: 6900 Loss: 0.0171 lr: 0.0000\n",
            "Step: 6950 Loss: 0.0128 lr: 0.0000\n",
            "Step: 7000 Loss: 0.0166 lr: 0.0000\n",
            "Step: 7050 Loss: 0.0151 lr: 0.0000\n",
            "Step: 7100 Loss: 0.0132 lr: 0.0000\n",
            "Step: 7150 Loss: 0.0146 lr: 0.0000\n",
            "Step: 7200 Loss: 0.0166 lr: 0.0000\n",
            "Step: 7250 Loss: 0.0153 lr: 0.0000\n",
            "Step: 7300 Loss: 0.0126 lr: 0.0000\n",
            "Step: 7350 Loss: 0.0134 lr: 0.0000\n",
            "Step: 7400 Loss: 0.0143 lr: 0.0000\n",
            "Step: 7450 Loss: 0.0231 lr: 0.0000\n",
            "Step: 7500 Loss: 0.0160 lr: 0.0000\n",
            "Step: 7550 Loss: 0.0141 lr: 0.0000\n",
            "Step: 7600 Loss: 0.0135 lr: 0.0000\n",
            "Step: 7650 Loss: 0.0140 lr: 0.0000\n",
            "Step: 7700 Loss: 0.0178 lr: 0.0000\n",
            "Step: 7750 Loss: 0.0137 lr: 0.0000\n",
            "Step: 7800 Loss: 0.0161 lr: 0.0000\n",
            "Step: 7850 Loss: 0.0177 lr: 0.0000\n",
            "Step: 7900 Loss: 0.0144 lr: 0.0000\n",
            "Step: 7950 Loss: 0.0113 lr: 0.0000\n",
            "Step: 8000 Loss: 0.0175 lr: 0.0000\n",
            "Step: 8050 Loss: 0.0163 lr: 0.0000\n",
            "Step: 8100 Loss: 0.0169 lr: 0.0000\n",
            "Step: 8150 Loss: 0.0138 lr: 0.0000\n",
            "Step: 8200 Loss: 0.0145 lr: 0.0000\n",
            "Step: 8250 Loss: 0.0116 lr: 0.0000\n",
            "Step: 8300 Loss: 0.0166 lr: 0.0000\n",
            "Step: 8350 Loss: 0.0177 lr: 0.0000\n",
            "Step: 8400 Loss: 0.0189 lr: 0.0000\n",
            "Step: 8450 Loss: 0.0162 lr: 0.0000\n",
            "Step: 8500 Loss: 0.0141 lr: 0.0000\n",
            "Step: 8550 Loss: 0.0129 lr: 0.0000\n",
            "Step: 8600 Loss: 0.0208 lr: 0.0000\n",
            "Step: 8650 Loss: 0.0157 lr: 0.0000\n",
            "Step: 8700 Loss: 0.0122 lr: 0.0000\n",
            "Step: 8750 Loss: 0.0162 lr: 0.0000\n",
            "Step: 8800 Loss: 0.0154 lr: 0.0000\n",
            "Step: 8850 Loss: 0.0135 lr: 0.0000\n",
            "Step: 8900 Loss: 0.0112 lr: 0.0000\n",
            "Step: 8950 Loss: 0.0264 lr: 0.0000\n",
            "Epoch 1 Total Mean Loss : 0.0215\n",
            "**Calculating validation results...**\n",
            "Epoch 1 Total Mean Score : 0.0055\n",
            "*****Epoch 1 Train Finished*****\n",
            "\n",
            "*****Epoch 2 Train Start*****\n",
            "*****Epoch 2 Total Step 8990*****\n",
            "Step: 50 Loss: 0.0132 lr: 0.0000\n",
            "Step: 100 Loss: 0.0133 lr: 0.0000\n",
            "Step: 150 Loss: 0.0138 lr: 0.0000\n",
            "Step: 200 Loss: 0.0141 lr: 0.0000\n",
            "Step: 250 Loss: 0.0173 lr: 0.0000\n",
            "Step: 300 Loss: 0.0139 lr: 0.0000\n",
            "Step: 350 Loss: 0.0163 lr: 0.0000\n",
            "Step: 400 Loss: 0.0115 lr: 0.0000\n",
            "Step: 450 Loss: 0.0156 lr: 0.0000\n",
            "Step: 500 Loss: 0.0180 lr: 0.0000\n",
            "Step: 550 Loss: 0.0166 lr: 0.0000\n",
            "Step: 600 Loss: 0.0116 lr: 0.0000\n",
            "Step: 650 Loss: 0.0136 lr: 0.0000\n",
            "Step: 700 Loss: 0.0157 lr: 0.0000\n",
            "Step: 750 Loss: 0.0155 lr: 0.0000\n",
            "Step: 800 Loss: 0.0179 lr: 0.0000\n",
            "Step: 850 Loss: 0.0196 lr: 0.0000\n",
            "Step: 900 Loss: 0.0164 lr: 0.0000\n",
            "Step: 950 Loss: 0.0171 lr: 0.0000\n",
            "Step: 1000 Loss: 0.0151 lr: 0.0000\n",
            "Step: 1050 Loss: 0.0138 lr: 0.0000\n",
            "Step: 1100 Loss: 0.0178 lr: 0.0000\n",
            "Step: 1150 Loss: 0.0163 lr: 0.0000\n",
            "Step: 1200 Loss: 0.0132 lr: 0.0000\n",
            "Step: 1250 Loss: 0.0170 lr: 0.0000\n",
            "Step: 1300 Loss: 0.0133 lr: 0.0000\n",
            "Step: 1350 Loss: 0.0141 lr: 0.0000\n",
            "Step: 1400 Loss: 0.0140 lr: 0.0000\n",
            "Step: 1450 Loss: 0.0127 lr: 0.0000\n",
            "Step: 1500 Loss: 0.0145 lr: 0.0000\n",
            "Step: 1550 Loss: 0.0113 lr: 0.0000\n",
            "Step: 1600 Loss: 0.0112 lr: 0.0000\n",
            "Step: 1650 Loss: 0.0109 lr: 0.0000\n",
            "Step: 1700 Loss: 0.0124 lr: 0.0000\n",
            "Step: 1750 Loss: 0.0160 lr: 0.0000\n",
            "Step: 1800 Loss: 0.0123 lr: 0.0000\n",
            "Step: 1850 Loss: 0.0162 lr: 0.0000\n",
            "Step: 1900 Loss: 0.0161 lr: 0.0000\n",
            "Step: 1950 Loss: 0.0134 lr: 0.0000\n",
            "Step: 2000 Loss: 0.0160 lr: 0.0000\n",
            "Step: 2050 Loss: 0.0127 lr: 0.0000\n",
            "Step: 2100 Loss: 0.0138 lr: 0.0000\n",
            "Step: 2150 Loss: 0.0131 lr: 0.0000\n",
            "Step: 2200 Loss: 0.0168 lr: 0.0000\n",
            "Step: 2250 Loss: 0.0156 lr: 0.0000\n",
            "Step: 2300 Loss: 0.0201 lr: 0.0000\n",
            "Step: 2350 Loss: 0.0116 lr: 0.0000\n",
            "Step: 2400 Loss: 0.0121 lr: 0.0000\n",
            "Step: 2450 Loss: 0.0155 lr: 0.0000\n",
            "Step: 2500 Loss: 0.0129 lr: 0.0000\n",
            "Step: 2550 Loss: 0.0105 lr: 0.0000\n",
            "Step: 2600 Loss: 0.0165 lr: 0.0000\n",
            "Step: 2650 Loss: 0.0136 lr: 0.0000\n",
            "Step: 2700 Loss: 0.0154 lr: 0.0000\n",
            "Step: 2750 Loss: 0.0184 lr: 0.0000\n",
            "Step: 2800 Loss: 0.0129 lr: 0.0000\n",
            "Step: 2850 Loss: 0.0124 lr: 0.0000\n",
            "Step: 2900 Loss: 0.0127 lr: 0.0000\n",
            "Step: 2950 Loss: 0.0144 lr: 0.0000\n",
            "Step: 3000 Loss: 0.0148 lr: 0.0000\n",
            "Step: 3050 Loss: 0.0140 lr: 0.0000\n",
            "Step: 3100 Loss: 0.0102 lr: 0.0000\n",
            "Step: 3150 Loss: 0.0185 lr: 0.0000\n",
            "Step: 3200 Loss: 0.0097 lr: 0.0000\n",
            "Step: 3250 Loss: 0.0126 lr: 0.0000\n",
            "Step: 3300 Loss: 0.0160 lr: 0.0000\n",
            "Step: 3350 Loss: 0.0162 lr: 0.0000\n",
            "Step: 3400 Loss: 0.0155 lr: 0.0000\n",
            "Step: 3450 Loss: 0.0119 lr: 0.0000\n",
            "Step: 3500 Loss: 0.0150 lr: 0.0000\n",
            "Step: 3550 Loss: 0.0137 lr: 0.0000\n",
            "Step: 3600 Loss: 0.0129 lr: 0.0000\n",
            "Step: 3650 Loss: 0.0142 lr: 0.0000\n",
            "Step: 3700 Loss: 0.0167 lr: 0.0000\n",
            "Step: 3750 Loss: 0.0169 lr: 0.0000\n",
            "Step: 3800 Loss: 0.0178 lr: 0.0000\n",
            "Step: 3850 Loss: 0.0112 lr: 0.0000\n",
            "Step: 3900 Loss: 0.0145 lr: 0.0000\n",
            "Step: 3950 Loss: 0.0167 lr: 0.0000\n",
            "Step: 4000 Loss: 0.0208 lr: 0.0000\n",
            "Step: 4050 Loss: 0.0184 lr: 0.0000\n",
            "Step: 4100 Loss: 0.0166 lr: 0.0000\n",
            "Step: 4150 Loss: 0.0167 lr: 0.0000\n",
            "Step: 4200 Loss: 0.0169 lr: 0.0000\n",
            "Step: 4250 Loss: 0.0090 lr: 0.0000\n",
            "Step: 4300 Loss: 0.0138 lr: 0.0000\n",
            "Step: 4350 Loss: 0.0158 lr: 0.0000\n",
            "Step: 4400 Loss: 0.0148 lr: 0.0000\n",
            "Step: 4450 Loss: 0.0130 lr: 0.0000\n",
            "Step: 4500 Loss: 0.0152 lr: 0.0000\n",
            "Step: 4550 Loss: 0.0160 lr: 0.0000\n",
            "Step: 4600 Loss: 0.0134 lr: 0.0000\n",
            "Step: 4650 Loss: 0.0169 lr: 0.0000\n",
            "Step: 4700 Loss: 0.0160 lr: 0.0000\n",
            "Step: 4750 Loss: 0.0139 lr: 0.0000\n",
            "Step: 4800 Loss: 0.0132 lr: 0.0000\n",
            "Step: 4850 Loss: 0.0173 lr: 0.0000\n",
            "Step: 4900 Loss: 0.0127 lr: 0.0000\n",
            "Step: 4950 Loss: 0.0129 lr: 0.0000\n",
            "Step: 5000 Loss: 0.0147 lr: 0.0000\n",
            "Step: 5050 Loss: 0.0180 lr: 0.0000\n",
            "Step: 5100 Loss: 0.0140 lr: 0.0000\n",
            "Step: 5150 Loss: 0.0163 lr: 0.0000\n",
            "Step: 5200 Loss: 0.0146 lr: 0.0000\n",
            "Step: 5250 Loss: 0.0175 lr: 0.0000\n",
            "Step: 5300 Loss: 0.0146 lr: 0.0000\n",
            "Step: 5350 Loss: 0.0169 lr: 0.0000\n",
            "Step: 5400 Loss: 0.0175 lr: 0.0000\n",
            "Step: 5450 Loss: 0.0177 lr: 0.0000\n",
            "Step: 5500 Loss: 0.0142 lr: 0.0000\n",
            "Step: 5550 Loss: 0.0137 lr: 0.0000\n",
            "Step: 5600 Loss: 0.0149 lr: 0.0000\n",
            "Step: 5650 Loss: 0.0162 lr: 0.0000\n",
            "Step: 5700 Loss: 0.0154 lr: 0.0000\n",
            "Step: 5750 Loss: 0.0151 lr: 0.0000\n",
            "Step: 5800 Loss: 0.0156 lr: 0.0000\n",
            "Step: 5850 Loss: 0.0143 lr: 0.0000\n",
            "Step: 5900 Loss: 0.0154 lr: 0.0000\n",
            "Step: 5950 Loss: 0.0130 lr: 0.0000\n",
            "Step: 6000 Loss: 0.0144 lr: 0.0000\n",
            "Step: 6050 Loss: 0.0148 lr: 0.0000\n",
            "Step: 6100 Loss: 0.0119 lr: 0.0000\n",
            "Step: 6150 Loss: 0.0140 lr: 0.0000\n",
            "Step: 6200 Loss: 0.0152 lr: 0.0000\n",
            "Step: 6250 Loss: 0.0131 lr: 0.0000\n",
            "Step: 6300 Loss: 0.0129 lr: 0.0000\n",
            "Step: 6350 Loss: 0.0135 lr: 0.0000\n",
            "Step: 6400 Loss: 0.0174 lr: 0.0000\n",
            "Step: 6450 Loss: 0.0169 lr: 0.0000\n",
            "Step: 6500 Loss: 0.0432 lr: 0.0000\n",
            "Step: 6550 Loss: 0.0130 lr: 0.0000\n",
            "Step: 6600 Loss: 0.0171 lr: 0.0000\n",
            "Step: 6650 Loss: 0.0366 lr: 0.0000\n",
            "Step: 6700 Loss: 0.0718 lr: 0.0000\n",
            "Step: 6750 Loss: 0.0549 lr: 0.0000\n",
            "Step: 6800 Loss: 0.0450 lr: 0.0000\n",
            "Step: 6850 Loss: 0.0349 lr: 0.0000\n",
            "Step: 6900 Loss: 0.0375 lr: 0.0000\n",
            "Step: 6950 Loss: 0.0431 lr: 0.0000\n",
            "Step: 7000 Loss: 0.0398 lr: 0.0000\n",
            "Step: 7050 Loss: 0.0320 lr: 0.0000\n",
            "Step: 7100 Loss: 0.0288 lr: 0.0000\n",
            "Step: 7150 Loss: 0.0294 lr: 0.0000\n",
            "Step: 7200 Loss: 0.0242 lr: 0.0000\n",
            "Step: 7250 Loss: 0.0253 lr: 0.0000\n",
            "Step: 7300 Loss: 0.0254 lr: 0.0000\n",
            "Step: 7350 Loss: 0.0254 lr: 0.0000\n",
            "Step: 7400 Loss: 0.0269 lr: 0.0000\n",
            "Step: 7450 Loss: 0.0199 lr: 0.0000\n",
            "Step: 7500 Loss: 0.0239 lr: 0.0000\n",
            "Step: 7550 Loss: 0.0244 lr: 0.0000\n",
            "Step: 7600 Loss: 0.0250 lr: 0.0000\n",
            "Step: 7650 Loss: 0.0390 lr: 0.0000\n",
            "Step: 7700 Loss: 0.0308 lr: 0.0000\n",
            "Step: 7750 Loss: 0.0301 lr: 0.0000\n",
            "Step: 7800 Loss: 0.0268 lr: 0.0000\n",
            "Step: 7850 Loss: 0.0352 lr: 0.0000\n",
            "Step: 7900 Loss: 0.0218 lr: 0.0000\n",
            "Step: 7950 Loss: 0.0225 lr: 0.0000\n",
            "Step: 8000 Loss: 0.0224 lr: 0.0000\n",
            "Step: 8050 Loss: 0.0220 lr: 0.0000\n",
            "Step: 8100 Loss: 0.0238 lr: 0.0000\n",
            "Step: 8150 Loss: 0.0245 lr: 0.0000\n",
            "Step: 8200 Loss: 0.0230 lr: 0.0000\n",
            "Step: 8250 Loss: 0.0277 lr: 0.0000\n",
            "Step: 8300 Loss: 0.0256 lr: 0.0000\n",
            "Step: 8350 Loss: 0.0229 lr: 0.0000\n",
            "Step: 8400 Loss: 0.0242 lr: 0.0000\n",
            "Step: 8450 Loss: 0.0240 lr: 0.0000\n",
            "Step: 8500 Loss: 0.0231 lr: 0.0000\n",
            "Step: 8550 Loss: 0.0267 lr: 0.0000\n",
            "Step: 8600 Loss: 0.0252 lr: 0.0000\n",
            "Step: 8650 Loss: 0.0218 lr: 0.0000\n",
            "Step: 8700 Loss: 0.0237 lr: 0.0000\n",
            "Step: 8750 Loss: 0.0178 lr: 0.0000\n",
            "Step: 8800 Loss: 0.0178 lr: 0.0000\n",
            "Step: 8850 Loss: 0.0153 lr: 0.0000\n",
            "Step: 8900 Loss: 0.0263 lr: 0.0000\n",
            "Step: 8950 Loss: 0.0260 lr: 0.0000\n",
            "Epoch 2 Total Mean Loss : 0.0186\n",
            "**Calculating validation results...**\n",
            "Epoch 2 Total Mean Score : 0.0098\n",
            "*****Epoch 2 Train Finished*****\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(text_input_ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zJ4dsB_Hao9H",
        "outputId": "92922bc9-de90-443e-dd1e-e7d895257535"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[    0, 14504, 14047,  ...,     3,     3,     3],\n",
            "        [    0, 21004,  9103,  ...,     3,     3,     3]], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(batch[\"sentence_input_ids\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hj8L7PvLat-y",
        "outputId": "4a50dc31-450f-4610-9d88-37d2336a9e56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[tensor([[    0, 14504, 14047, 12080, 14087, 13328, 15494, 17932, 14047, 11821,\n",
            "         14378, 12060, 14497, 18374, 14596, 18374, 14032, 17923, 22581, 14899,\n",
            "         14255, 14032, 14821, 15550, 14087, 12943, 14895, 17612, 14121, 22214,\n",
            "         14533,     1],\n",
            "        [    0, 17134, 14504, 14047, 12080, 14087, 13328, 14415, 11280, 24539,\n",
            "         16201, 15686, 14558, 15482,  8981, 29465, 28228, 14806, 14938, 11776,\n",
            "         15989, 15286, 14207, 14455, 15240, 15665, 15743, 24227, 19025, 11280,\n",
            "         14025,     1]]), tensor([[    0, 21004,  9103, 14143, 14031,  9092, 23999, 15494, 14733, 18784,\n",
            "         14031,  9092, 12130, 15236, 16959, 15221, 14036, 14479, 13173,  9545,\n",
            "         17819, 23469, 20683, 16395, 14025,  9754, 17546,     1,     3,     3,\n",
            "             3,     3],\n",
            "        [    0, 14438, 11806, 14806, 27026, 14623, 15053, 15487, 17289, 19539,\n",
            "         17960, 17486, 14158, 12141, 14641, 18294, 15880, 12123, 20008, 26497,\n",
            "         19787, 21283, 16390, 15004, 16304, 14894, 11465,  1700, 14147, 14438,\n",
            "         11806,     1],\n",
            "        [    0, 14602, 14438, 11806, 14806, 14834, 15276, 15004, 16831, 14256,\n",
            "         25792, 14245, 22443, 20086, 19195,  9123, 19933, 12972, 10439, 20965,\n",
            "         14143, 23999, 18482, 24715,  1700, 14889,   300, 15054,   264,   268,\n",
            "           288,     1],\n",
            "        [    0, 14834, 16831, 14143, 14031,  9092, 14338, 15418, 29739, 14470,\n",
            "           300, 19542, 14889,   314, 22554,  1543, 14143, 15085,   307, 28171,\n",
            "         23999, 23627, 14464, 14206, 22655, 14143, 14031,  9092, 23999, 14623,\n",
            "         14236,     1],\n",
            "        [    0, 14834, 16831, 14143, 14031,  9092, 14338, 15418, 29739, 14470,\n",
            "           300, 19542, 14889,   314, 22554,  1543, 14143, 15085,   307, 28171,\n",
            "         23999, 23627, 14464, 14206, 22655, 14143, 14031,  9092, 23999, 14623,\n",
            "         14236,     1]])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model-Load & Inference"
      ],
      "metadata": {
        "id": "C_RROs-6spd7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount(\"/content/drive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-spC_hkCSB1j",
        "outputId": "d45b5346-9e41-40ec-e53c-3e48254c3015"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/drive/MyDrive/Summary_task/Validation/valid_original.json\") as f:\n",
        "  json_data_val = json.load(f)"
      ],
      "metadata": {
        "id": "GN1u4fIuSrkZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "documents = json_data_val[\"documents\"]\n",
        "df_val = pd.DataFrame(columns=['TITLE','ABS_SUM','CONTENT'])\n",
        "\n",
        "for document in tqdm(documents[:20000]):\n",
        "    stc_list = []\n",
        "    \n",
        "    for j in document['text'][2:]:\n",
        "        if j == [] : continue\n",
        "        stc_list.append(j[0][\"sentence\"])\n",
        "            \n",
        "    df_val = df_val.append(pd.DataFrame([[document['title'],document['abstractive'][0],stc_list]], columns=['TITLE','ABS_SUM','CONTENT']), ignore_index=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oxRcq-ZnThZi",
        "outputId": "1bd7b8d4-6c84-453f-ab4b-ff3a7d15b053"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20000/20000 [00:27<00:00, 734.94it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_val.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "dD3EaGLNnnVG",
        "outputId": "93e2ebb3-235e-4538-f163-e8f7f5bf6bd3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            TITLE  \\\n",
              "0                      文대통령 \"5G는 4차산업혁명 시대의 고속도로\"   \n",
              "1                  \"손학규 물러나라\"...바른계, 최고위 회의 '보이콧'   \n",
              "2               \"마치 한 장소처럼\" ... 5G로 서울·부산·광주 원격협연   \n",
              "3  \"이웃도 모르는데, 이게 서울 미래냐\"...'고층 재개발 요구' 작심 비판한 박원순   \n",
              "4               \"SK·알파벳 벤치마킹해야\"...KB운용, KMH에 주주서한   \n",
              "\n",
              "                                             ABS_SUM  \\\n",
              "0  8일 서울에서 열린 5G플러스 전략발표에 참석한 문재인 대통령은 5G는 대한민국 혁...   \n",
              "1  8일 바른미래당 최고의원 회의에 하태경 의원 등 5명의 최고의원이 지도부 퇴진을 요...   \n",
              "2  지난 3일 한국이 세계 첫 5세대 이동통신 서비스를 보편화한 것을 축하하는 '코리안...   \n",
              "3  박원순 서울시장은 8일 서울시청에서 열린 '골목길 재생 시민 정책 대화'에 참석하여...   \n",
              "4  주주가치 포커스를 운용하는 KB자산운용이  SK와 알파벳(구글 지주회사)의 모범적 ...   \n",
              "\n",
              "                                             CONTENT  \n",
              "0  [문 대통령은 \"5G가 각 분야에 융합되면, 정보통신산업을 넘어 자동차, 드론(무인...  \n",
              "1  [손 대표는 회의를 주재하면서 \"의원들이나 지역위원장들, 당원들이 다음 선거에 대해...  \n",
              "2  [그러나 이 공연은 5G 이동통신의 실시간 전송기술을 활용해 서울과 부산, 광주에서...  \n",
              "3  [박 시장은 \"여러분 제가 피 흘리고 서 있는 게 안 보이시나요. 저를 상대로 얼마...  \n",
              "4  [SK와 알파벳은 신규 투자는 지주회사가 전담하고, 자회사는 본업에만 충실할 수 있...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cc85b54c-1ef9-477c-982d-6c46462d8201\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TITLE</th>\n",
              "      <th>ABS_SUM</th>\n",
              "      <th>CONTENT</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>文대통령 \"5G는 4차산업혁명 시대의 고속도로\"</td>\n",
              "      <td>8일 서울에서 열린 5G플러스 전략발표에 참석한 문재인 대통령은 5G는 대한민국 혁...</td>\n",
              "      <td>[문 대통령은 \"5G가 각 분야에 융합되면, 정보통신산업을 넘어 자동차, 드론(무인...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\"손학규 물러나라\"...바른계, 최고위 회의 '보이콧'</td>\n",
              "      <td>8일 바른미래당 최고의원 회의에 하태경 의원 등 5명의 최고의원이 지도부 퇴진을 요...</td>\n",
              "      <td>[손 대표는 회의를 주재하면서 \"의원들이나 지역위원장들, 당원들이 다음 선거에 대해...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>\"마치 한 장소처럼\" ... 5G로 서울·부산·광주 원격협연</td>\n",
              "      <td>지난 3일 한국이 세계 첫 5세대 이동통신 서비스를 보편화한 것을 축하하는 '코리안...</td>\n",
              "      <td>[그러나 이 공연은 5G 이동통신의 실시간 전송기술을 활용해 서울과 부산, 광주에서...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\"이웃도 모르는데, 이게 서울 미래냐\"...'고층 재개발 요구' 작심 비판한 박원순</td>\n",
              "      <td>박원순 서울시장은 8일 서울시청에서 열린 '골목길 재생 시민 정책 대화'에 참석하여...</td>\n",
              "      <td>[박 시장은 \"여러분 제가 피 흘리고 서 있는 게 안 보이시나요. 저를 상대로 얼마...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>\"SK·알파벳 벤치마킹해야\"...KB운용, KMH에 주주서한</td>\n",
              "      <td>주주가치 포커스를 운용하는 KB자산운용이  SK와 알파벳(구글 지주회사)의 모범적 ...</td>\n",
              "      <td>[SK와 알파벳은 신규 투자는 지주회사가 전담하고, 자회사는 본업에만 충실할 수 있...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cc85b54c-1ef9-477c-982d-6c46462d8201')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-cc85b54c-1ef9-477c-982d-6c46462d8201 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-cc85b54c-1ef9-477c-982d-6c46462d8201');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train data 와 같은 전처리를 적용한다.\n",
        "\n",
        "# 한국어 불용어 리스트 크롤링\n",
        "\n",
        "\n",
        "url = \"https://www.ranks.nl/stopwords/korean\"\n",
        "response = requests.get(url, verify = False)\n",
        "\n",
        "if response.status_code == 200:\n",
        "    soup = BeautifulSoup(response.text,'html.parser')\n",
        "    content = soup.select_one('#article178ebefbfb1b165454ec9f168f545239 > div.panel-body > table > tbody > tr')\n",
        "    stop_words=[]\n",
        "    for x in content.strings:\n",
        "        x=x.strip()\n",
        "        if x:\n",
        "            stop_words.append(x)\n",
        "    print(f\"# Korean stop words: {len(stop_words)}\")\n",
        "else:\n",
        "    print(response.status_code)\n",
        "\n",
        "okt = Okt()\n",
        "\n",
        "def title_tokenizing(x):\n",
        "    temp_data = okt.morphs(x)\n",
        "    temp_list = []\n",
        "    for word in temp_data:\n",
        "        if word in stop_words: \n",
        "            continue\n",
        "        temp_list.append(word)\n",
        "  \n",
        "    return \" \".join(temp_list)\n",
        "    \n",
        "    \n",
        "def content_tokenizing(x):\n",
        "    new_list = list(filter(None, x))\n",
        "    \n",
        "    final_list = []\n",
        "    for i in new_list:\n",
        "        temp_data = okt.morphs(i)\n",
        "        temp_list = []\n",
        "        for word in temp_data:\n",
        "            if word in stop_words:\n",
        "                continue\n",
        "            temp_list.append(word)\n",
        "        final_list.append(\" \".join(temp_list))\n",
        "\n",
        "    return final_list\n",
        "\n",
        "# input_id 가 들어오면 문장 앞뒤로 cls,sep토큰을 붙여주고 길이에 맞춰 padding을 해준다.\n",
        "# 문장을 여러 개 합친 조합을 하나의 문장으로 처리해야 하기에 따로 함수가 필요하다\n",
        "\n",
        "def control_input_ids(input_ids_tensor,length,cls_token_num,sep_token_num,pad_token_num): \n",
        "  cur_length = len(input_ids_tensor)\n",
        "  cls_token = torch.tensor([cls_token_num])\n",
        "  sep_token = torch.tensor([sep_token_num])\n",
        "\n",
        "  if cur_length+2 > length:\n",
        "    input_ids_tensor = input_ids_tensor[:length-2]  # 길이가 넘치면 자른다\n",
        "    return torch.cat([cls_token,input_ids_tensor,sep_token])\n",
        "  else:\n",
        "    input_ids_tensor = torch.cat([cls_token,input_ids_tensor,sep_token])\n",
        "    padding_list = torch.tensor([pad_token_num]*(length - cur_length -2)) # 길이가 모자라면 padding token 을 채운다\n",
        "    return torch.cat([input_ids_tensor,padding_list])"
      ],
      "metadata": {
        "id": "E1dvsC-WUXA8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42f539f2-1eea-4fdc-9039-8190b845cb06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py:988: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.ranks.nl'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
            "  InsecureRequestWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# Korean stop words: 677\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_tokenized_val = pd.DataFrame()\n",
        "df_tokenized_val['TITLE'] = df_val['TITLE'].progress_apply(lambda x: title_tokenizing(x))\n",
        "df_tokenized_val['ABS_SUM'] = df_val['ABS_SUM'].progress_apply(lambda x: title_tokenizing(x))\n",
        "df_tokenized_val['CONTENT'] = df_val['CONTENT'].progress_apply(lambda x: content_tokenizing(x))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hW-PflE2TiMe",
        "outputId": "6054699d-cae4-4485-8cf3-a4b79f9082cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20000/20000 [00:37<00:00, 536.86it/s]\n",
            "100%|██████████| 20000/20000 [03:10<00:00, 104.91it/s]\n",
            "100%|██████████| 20000/20000 [10:34<00:00, 31.51it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_tokenized_val.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        },
        "id": "2WMyB2Ehn-XP",
        "outputId": "76ad8b84-6106-4c20-d659-3d9d5a86e4b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               TITLE  \\\n",
              "0                   文 대통령 \" 5 G 는 4 차 산업혁명 시대 고속도로 \"   \n",
              "1              \" 손학규 물러나라 \"... 바른계 , 최고 위 회의 ' 보이콧 '   \n",
              "2              \" 한 장소 처럼 \" ... 5 G 서울 · 부산 · 광주 원격협연   \n",
              "3  \" 이웃 도 모르는데 , 게 서울 미래 냐 \"...' 고층 재개발 요구 ' 작심 비...   \n",
              "4          \" SK · 알파벳 벤치마킹 해야 \"... KB 운용 , KMH 주주 서한   \n",
              "\n",
              "                                             ABS_SUM  \\\n",
              "0  8일 서울 열린 5 G 플러스 전략 발표 참석 한 문재인 대통령 은 5 G 는 대한...   \n",
              "1  8일 바른 미래 당 최고 의원 회의 하태경 의원 5 명의 최고 의원 지 도부 퇴진 ...   \n",
              "2  지난 3일 한국 세계 첫 5 세대 이동통신 서비스 보편화 한 축하 하는 ' 코리안 ...   \n",
              "3  박원순 서울시장 은 8일 서 울 시청 열린 ' 골목길 재생 시민 정책 대화 ' 참석...   \n",
              "4  주주 가치 포커스 운용 하는 KB 자산운용 SK 알파벳 ( 구글 지주회사 ) 모범 ...   \n",
              "\n",
              "                                             CONTENT  \n",
              "0  [문 대통령 은 \" 5 G 분야 융합 되면 , 정보통 신 산업 넘어 자동차 , 드론...  \n",
              "1  [손 대표 는 회의 주재 \" 의원 이나 지역 위원장 , 당원 선거 대해 불안하게 생...  \n",
              "2  [공연 은 5 G 이동통신 실시간 전송 기술 활용 해 서울 부산 , 광주 동시 하는...  \n",
              "3  [박 시장 은 \" 피 흘리고 서 있는 게 안 보이시나요 . 상대로 많은 사람 층 고...  \n",
              "4  [SK 알파벳 은 신규 투자 는 지주회사 전담 하고 , 자회사 는 본업 에만 충실할...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-dd253039-359e-4d55-b17a-d1202aae38d3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TITLE</th>\n",
              "      <th>ABS_SUM</th>\n",
              "      <th>CONTENT</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>文 대통령 \" 5 G 는 4 차 산업혁명 시대 고속도로 \"</td>\n",
              "      <td>8일 서울 열린 5 G 플러스 전략 발표 참석 한 문재인 대통령 은 5 G 는 대한...</td>\n",
              "      <td>[문 대통령 은 \" 5 G 분야 융합 되면 , 정보통 신 산업 넘어 자동차 , 드론...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\" 손학규 물러나라 \"... 바른계 , 최고 위 회의 ' 보이콧 '</td>\n",
              "      <td>8일 바른 미래 당 최고 의원 회의 하태경 의원 5 명의 최고 의원 지 도부 퇴진 ...</td>\n",
              "      <td>[손 대표 는 회의 주재 \" 의원 이나 지역 위원장 , 당원 선거 대해 불안하게 생...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>\" 한 장소 처럼 \" ... 5 G 서울 · 부산 · 광주 원격협연</td>\n",
              "      <td>지난 3일 한국 세계 첫 5 세대 이동통신 서비스 보편화 한 축하 하는 ' 코리안 ...</td>\n",
              "      <td>[공연 은 5 G 이동통신 실시간 전송 기술 활용 해 서울 부산 , 광주 동시 하는...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\" 이웃 도 모르는데 , 게 서울 미래 냐 \"...' 고층 재개발 요구 ' 작심 비...</td>\n",
              "      <td>박원순 서울시장 은 8일 서 울 시청 열린 ' 골목길 재생 시민 정책 대화 ' 참석...</td>\n",
              "      <td>[박 시장 은 \" 피 흘리고 서 있는 게 안 보이시나요 . 상대로 많은 사람 층 고...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>\" SK · 알파벳 벤치마킹 해야 \"... KB 운용 , KMH 주주 서한</td>\n",
              "      <td>주주 가치 포커스 운용 하는 KB 자산운용 SK 알파벳 ( 구글 지주회사 ) 모범 ...</td>\n",
              "      <td>[SK 알파벳 은 신규 투자 는 지주회사 전담 하고 , 자회사 는 본업 에만 충실할...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dd253039-359e-4d55-b17a-d1202aae38d3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-dd253039-359e-4d55-b17a-d1202aae38d3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-dd253039-359e-4d55-b17a-d1202aae38d3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "idx_list = []\n",
        "for i in range(len(df_tokenized_val)):\n",
        "    sentence_list = df_tokenized_val['CONTENT'].iloc[i]\n",
        "    if len(sentence_list) == 0:\n",
        "        idx_list.append(i)\n",
        "\n",
        "df_tokenized_val = df_tokenized_val.drop(idx_list)"
      ],
      "metadata": {
        "id": "24arzof0fe_Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(df_tokenized_val)):\n",
        "    sentence_list = df_tokenized_val['CONTENT'].iloc[i]\n",
        "    if len(sentence_list) == 0:\n",
        "        print(i)"
      ],
      "metadata": {
        "id": "sjmqm4IKfwkS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = BartModel.from_pretrained(get_pytorch_kobart_model())\n",
        "model.load_state_dict(state_dict = torch.load(\"/content/drive/MyDrive/Summary_task/kobart_model_1epoch.pth\"))\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pB9HNaN1sogy",
        "outputId": "c0f45c49-540a-4805-915d-9ed5267db054"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/.cache/kobart_base_cased_ff4bda5738.zip[██████████████████████████████████████████████████]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BartModel(\n",
              "  (shared): Embedding(30000, 768, padding_idx=3)\n",
              "  (encoder): BartEncoder(\n",
              "    (embed_tokens): Embedding(30000, 768, padding_idx=3)\n",
              "    (embed_positions): BartLearnedPositionalEmbedding(1028, 768, padding_idx=3)\n",
              "    (layers): ModuleList(\n",
              "      (0): BartEncoderLayer(\n",
              "        (self_attn): BartAttention(\n",
              "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        )\n",
              "        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "      (1): BartEncoderLayer(\n",
              "        (self_attn): BartAttention(\n",
              "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        )\n",
              "        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "      (2): BartEncoderLayer(\n",
              "        (self_attn): BartAttention(\n",
              "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        )\n",
              "        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "      (3): BartEncoderLayer(\n",
              "        (self_attn): BartAttention(\n",
              "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        )\n",
              "        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "      (4): BartEncoderLayer(\n",
              "        (self_attn): BartAttention(\n",
              "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        )\n",
              "        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "      (5): BartEncoderLayer(\n",
              "        (self_attn): BartAttention(\n",
              "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        )\n",
              "        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "    )\n",
              "    (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (decoder): BartDecoder(\n",
              "    (embed_tokens): Embedding(30000, 768, padding_idx=3)\n",
              "    (embed_positions): BartLearnedPositionalEmbedding(1028, 768, padding_idx=3)\n",
              "    (layers): ModuleList(\n",
              "      (0): BartDecoderLayer(\n",
              "        (self_attn): BartAttention(\n",
              "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        )\n",
              "        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (encoder_attn): BartAttention(\n",
              "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        )\n",
              "        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "      (1): BartDecoderLayer(\n",
              "        (self_attn): BartAttention(\n",
              "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        )\n",
              "        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (encoder_attn): BartAttention(\n",
              "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        )\n",
              "        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "      (2): BartDecoderLayer(\n",
              "        (self_attn): BartAttention(\n",
              "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        )\n",
              "        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (encoder_attn): BartAttention(\n",
              "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        )\n",
              "        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "      (3): BartDecoderLayer(\n",
              "        (self_attn): BartAttention(\n",
              "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        )\n",
              "        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (encoder_attn): BartAttention(\n",
              "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        )\n",
              "        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "      (4): BartDecoderLayer(\n",
              "        (self_attn): BartAttention(\n",
              "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        )\n",
              "        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (encoder_attn): BartAttention(\n",
              "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        )\n",
              "        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "      (5): BartDecoderLayer(\n",
              "        (self_attn): BartAttention(\n",
              "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        )\n",
              "        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (encoder_attn): BartAttention(\n",
              "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        )\n",
              "        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "    )\n",
              "    (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.to(device)\n",
        "summary_model = MatchSum(encoder = model, candidate_num = 1,device = device, hidden_size=768) "
      ],
      "metadata": {
        "id": "vep3ydW4stow"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def to_total(x):\n",
        "  total_str = \"\"\n",
        "  for sentence in x:\n",
        "    total_str += \" \"\n",
        "    total_str += sentence\n",
        "  \n",
        "  return total_str\n",
        "\n",
        "class get_ids():\n",
        "    def __init__(self,tokenizer):\n",
        "      self.tokenizer = tokenizer\n",
        "\n",
        "    def __call__(self, sentence):\n",
        "      ids = self.tokenizer(sentence)['input_ids']\n",
        "      ids = torch.tensor(ids)\n",
        "      return control_input_ids(ids,32,0,2,1).unsqueeze(0).to(torch.int64)\n",
        "\n",
        "class get_list_ids():\n",
        "    def __init__(self,tokenizer,device):\n",
        "      self.tokenizer = tokenizer\n",
        "      self.device = device\n",
        "    def __call__(self, sentence_list):\n",
        "\n",
        "      ans = torch.empty((0,32),dtype = torch.int64).to(self.device)\n",
        "      for sentence in sentence_list:\n",
        "        ids = self.tokenizer(sentence)['input_ids']\n",
        "        ids = torch.tensor(ids,dtype = torch.int64)\n",
        "        ans = torch.cat([ans,control_input_ids(ids,32,0,2,1).unsqueeze(0).to(torch.int64).to(device)],dim=0)\n",
        "      return [ans]"
      ],
      "metadata": {
        "id": "c_LzyTWrsv3b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = get_kobart_tokenizer()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bv3Jw_NscuIR",
        "outputId": "f9035a02-7e4e-4f7f-9412-fed7c476ee05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/.cache/kobart_base_tokenizer_cased_cf74400bce.zip[██████████████████████████████████████████████████]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ids_class = get_ids(tokenizer)\n",
        "ids_list_class = get_list_ids(tokenizer,device)"
      ],
      "metadata": {
        "id": "2LRNLdv1sxjD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_tokenized_val[\"text\"] = df_tokenized_val[\"CONTENT\"].apply(lambda x: to_total(x))\n",
        "df_tokenized_val[\"text_ids\"] = df_tokenized_val[\"text\"].apply(lambda x: ids_class(x))\n",
        "df_tokenized_val[\"label_ids\"] = df_tokenized_val[\"TITLE\"].apply(lambda x: ids_class(x))\n",
        "df_tokenized_val['list_of_sentence_ids'] = df_tokenized_val[\"CONTENT\"].progress_apply(lambda x: ids_list_class(x))"
      ],
      "metadata": {
        "id": "XFCULeK1sy5W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b4a5beb-8691-4763-8d4d-771dd62a019b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 19764/19764 [00:36<00:00, 537.86it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_tokenized_val['model_answer'] = df_tokenized_val[\"CONTENT\"]\n",
        "for i in tqdm(range(len(df_tokenized_val))):\n",
        "    try:\n",
        "        output = summary_model.forward(df_tokenized_val[\"text_ids\"].iloc[i].to(device),df_tokenized_val[\"label_ids\"][i].to(device),df_tokenized_val['list_of_sentence_ids'].iloc[i])\n",
        "        df_tokenized_val['model_answer'].iloc[i] = output['golden_summary'].detach().cpu().numpy()\n",
        "    except: continue"
      ],
      "metadata": {
        "id": "e5aD0tOWs0ui",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ecdb355-7945-4a08-f0cc-cc5cf7f76512"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 19764/19764 [2:05:06<00:00,  2.63it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_tokenized_val.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "I0fKA5boI4EW",
        "outputId": "6ab52eca-1547-4d19-a6d3-6afa6b75ccbd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               TITLE  \\\n",
              "0                   文 대통령 \" 5 G 는 4 차 산업혁명 시대 고속도로 \"   \n",
              "1              \" 손학규 물러나라 \"... 바른계 , 최고 위 회의 ' 보이콧 '   \n",
              "2              \" 한 장소 처럼 \" ... 5 G 서울 · 부산 · 광주 원격협연   \n",
              "3  \" 이웃 도 모르는데 , 게 서울 미래 냐 \"...' 고층 재개발 요구 ' 작심 비...   \n",
              "4          \" SK · 알파벳 벤치마킹 해야 \"... KB 운용 , KMH 주주 서한   \n",
              "\n",
              "                                             ABS_SUM  \\\n",
              "0  8일 서울 열린 5 G 플러스 전략 발표 참석 한 문재인 대통령 은 5 G 는 대한...   \n",
              "1  8일 바른 미래 당 최고 의원 회의 하태경 의원 5 명의 최고 의원 지 도부 퇴진 ...   \n",
              "2  지난 3일 한국 세계 첫 5 세대 이동통신 서비스 보편화 한 축하 하는 ' 코리안 ...   \n",
              "3  박원순 서울시장 은 8일 서 울 시청 열린 ' 골목길 재생 시민 정책 대화 ' 참석...   \n",
              "4  주주 가치 포커스 운용 하는 KB 자산운용 SK 알파벳 ( 구글 지주회사 ) 모범 ...   \n",
              "\n",
              "                                             CONTENT  \\\n",
              "0  [문 대통령 은 \" 5 G 분야 융합 되면 , 정보통 신 산업 넘어 자동차 , 드론...   \n",
              "1  [손 대표 는 회의 주재 \" 의원 이나 지역 위원장 , 당원 선거 대해 불안하게 생...   \n",
              "2  [공연 은 5 G 이동통신 실시간 전송 기술 활용 해 서울 부산 , 광주 동시 하는...   \n",
              "3  [박 시장 은 \" 피 흘리고 서 있는 게 안 보이시나요 . 상대로 많은 사람 층 고...   \n",
              "4  [SK 알파벳 은 신규 투자 는 지주회사 전담 하고 , 자회사 는 본업 에만 충실할...   \n",
              "\n",
              "                                                text  \\\n",
              "0   문 대통령 은 \" 5 G 분야 융합 되면 , 정보통 신 산업 넘어 자동차 , 드론...   \n",
              "1   손 대표 는 회의 주재 \" 의원 이나 지역 위원장 , 당원 선거 대해 불안하게 생...   \n",
              "2   공연 은 5 G 이동통신 실시간 전송 기술 활용 해 서울 부산 , 광주 동시 하는...   \n",
              "3   박 시장 은 \" 피 흘리고 서 있는 게 안 보이시나요 . 상대로 많은 사람 층 고...   \n",
              "4   SK 알파벳 은 신규 투자 는 지주회사 전담 하고 , 자회사 는 본업 에만 충실할...   \n",
              "\n",
              "                                            text_ids  \\\n",
              "0  [[tensor(0), tensor(14111), tensor(14305), ten...   \n",
              "1  [[tensor(0), tensor(14316), tensor(14328), ten...   \n",
              "2  [[tensor(0), tensor(15379), tensor(14806), ten...   \n",
              "3  [[tensor(0), tensor(14169), tensor(14558), ten...   \n",
              "4  [[tensor(0), tensor(15517), tensor(28214), ten...   \n",
              "\n",
              "                                           label_ids  \\\n",
              "0  [[tensor(0), tensor(1700), tensor(4361), tenso...   \n",
              "1  [[tensor(0), tensor(14050), tensor(14316), ten...   \n",
              "2  [[tensor(0), tensor(14050), tensor(14036), ten...   \n",
              "3  [[tensor(0), tensor(14050), tensor(18049), ten...   \n",
              "4  [[tensor(0), tensor(14050), tensor(15517), ten...   \n",
              "\n",
              "                                list_of_sentence_ids  \\\n",
              "0  [[[tensor(0, device='cuda:0'), tensor(14111, d...   \n",
              "1  [[[tensor(0, device='cuda:0'), tensor(14316, d...   \n",
              "2  [[[tensor(0, device='cuda:0'), tensor(15379, d...   \n",
              "3  [[[tensor(0, device='cuda:0'), tensor(14169, d...   \n",
              "4  [[[tensor(0, device='cuda:0'), tensor(15517, d...   \n",
              "\n",
              "                                        model_answer  \n",
              "0  [[0, 14111, 14305, 14806, 14050, 14144, 15464,...  \n",
              "1  [[0, 14316, 14328, 15494, 15915, 21439, 14050,...  \n",
              "2  [[0, 16414, 14305, 15004, 14554, 28492, 14062,...  \n",
              "3  [[0, 14169, 14558, 14806, 14050, 14250, 15910,...  \n",
              "4  [[0, 15517, 28214, 10860, 14806, 16173, 14559,...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-766f9503-9004-4f65-80ea-b202259ddb74\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TITLE</th>\n",
              "      <th>ABS_SUM</th>\n",
              "      <th>CONTENT</th>\n",
              "      <th>text</th>\n",
              "      <th>text_ids</th>\n",
              "      <th>label_ids</th>\n",
              "      <th>list_of_sentence_ids</th>\n",
              "      <th>model_answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>文 대통령 \" 5 G 는 4 차 산업혁명 시대 고속도로 \"</td>\n",
              "      <td>8일 서울 열린 5 G 플러스 전략 발표 참석 한 문재인 대통령 은 5 G 는 대한...</td>\n",
              "      <td>[문 대통령 은 \" 5 G 분야 융합 되면 , 정보통 신 산업 넘어 자동차 , 드론...</td>\n",
              "      <td>문 대통령 은 \" 5 G 분야 융합 되면 , 정보통 신 산업 넘어 자동차 , 드론...</td>\n",
              "      <td>[[tensor(0), tensor(14111), tensor(14305), ten...</td>\n",
              "      <td>[[tensor(0), tensor(1700), tensor(4361), tenso...</td>\n",
              "      <td>[[[tensor(0, device='cuda:0'), tensor(14111, d...</td>\n",
              "      <td>[[0, 14111, 14305, 14806, 14050, 14144, 15464,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\" 손학규 물러나라 \"... 바른계 , 최고 위 회의 ' 보이콧 '</td>\n",
              "      <td>8일 바른 미래 당 최고 의원 회의 하태경 의원 5 명의 최고 의원 지 도부 퇴진 ...</td>\n",
              "      <td>[손 대표 는 회의 주재 \" 의원 이나 지역 위원장 , 당원 선거 대해 불안하게 생...</td>\n",
              "      <td>손 대표 는 회의 주재 \" 의원 이나 지역 위원장 , 당원 선거 대해 불안하게 생...</td>\n",
              "      <td>[[tensor(0), tensor(14316), tensor(14328), ten...</td>\n",
              "      <td>[[tensor(0), tensor(14050), tensor(14316), ten...</td>\n",
              "      <td>[[[tensor(0, device='cuda:0'), tensor(14316, d...</td>\n",
              "      <td>[[0, 14316, 14328, 15494, 15915, 21439, 14050,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>\" 한 장소 처럼 \" ... 5 G 서울 · 부산 · 광주 원격협연</td>\n",
              "      <td>지난 3일 한국 세계 첫 5 세대 이동통신 서비스 보편화 한 축하 하는 ' 코리안 ...</td>\n",
              "      <td>[공연 은 5 G 이동통신 실시간 전송 기술 활용 해 서울 부산 , 광주 동시 하는...</td>\n",
              "      <td>공연 은 5 G 이동통신 실시간 전송 기술 활용 해 서울 부산 , 광주 동시 하는...</td>\n",
              "      <td>[[tensor(0), tensor(15379), tensor(14806), ten...</td>\n",
              "      <td>[[tensor(0), tensor(14050), tensor(14036), ten...</td>\n",
              "      <td>[[[tensor(0, device='cuda:0'), tensor(15379, d...</td>\n",
              "      <td>[[0, 16414, 14305, 15004, 14554, 28492, 14062,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\" 이웃 도 모르는데 , 게 서울 미래 냐 \"...' 고층 재개발 요구 ' 작심 비...</td>\n",
              "      <td>박원순 서울시장 은 8일 서 울 시청 열린 ' 골목길 재생 시민 정책 대화 ' 참석...</td>\n",
              "      <td>[박 시장 은 \" 피 흘리고 서 있는 게 안 보이시나요 . 상대로 많은 사람 층 고...</td>\n",
              "      <td>박 시장 은 \" 피 흘리고 서 있는 게 안 보이시나요 . 상대로 많은 사람 층 고...</td>\n",
              "      <td>[[tensor(0), tensor(14169), tensor(14558), ten...</td>\n",
              "      <td>[[tensor(0), tensor(14050), tensor(18049), ten...</td>\n",
              "      <td>[[[tensor(0, device='cuda:0'), tensor(14169, d...</td>\n",
              "      <td>[[0, 14169, 14558, 14806, 14050, 14250, 15910,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>\" SK · 알파벳 벤치마킹 해야 \"... KB 운용 , KMH 주주 서한</td>\n",
              "      <td>주주 가치 포커스 운용 하는 KB 자산운용 SK 알파벳 ( 구글 지주회사 ) 모범 ...</td>\n",
              "      <td>[SK 알파벳 은 신규 투자 는 지주회사 전담 하고 , 자회사 는 본업 에만 충실할...</td>\n",
              "      <td>SK 알파벳 은 신규 투자 는 지주회사 전담 하고 , 자회사 는 본업 에만 충실할...</td>\n",
              "      <td>[[tensor(0), tensor(15517), tensor(28214), ten...</td>\n",
              "      <td>[[tensor(0), tensor(14050), tensor(15517), ten...</td>\n",
              "      <td>[[[tensor(0, device='cuda:0'), tensor(15517, d...</td>\n",
              "      <td>[[0, 15517, 28214, 10860, 14806, 16173, 14559,...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-766f9503-9004-4f65-80ea-b202259ddb74')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-766f9503-9004-4f65-80ea-b202259ddb74 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-766f9503-9004-4f65-80ea-b202259ddb74');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_tokenized_val['model_answer_sentence'] = df_tokenized_val['model_answer']\n",
        "for i in range(len(df_tokenized_val)):\n",
        "    try : df_tokenized_val['model_answer_sentence'].iloc[i] = tokenizer.decode(token_ids = df_tokenized_val['model_answer'].iloc[i][0], skip_special_tokens = True)\n",
        "    except: df_tokenized_val['model_answer_sentence'].iloc[i] = \"error_sentence\"\n"
      ],
      "metadata": {
        "id": "VpevnK2os2UV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_tokenized_val_new = df_tokenized_val[['TITLE','text','model_answer_sentence']]\n",
        "df_tokenized_val_new.to_csv(\"/content/drive/MyDrive/temp_df.csv\",mode = 'w')"
      ],
      "metadata": {
        "id": "atrJ0xtSs4cy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "idx = 27\n",
        "print(df_tokenized_val_new['TITLE'].iloc[idx])\n",
        "print(df_tokenized_val_new['text'].iloc[idx])\n",
        "print(df_tokenized_val_new['model_answer_sentence'].iloc[idx])"
      ],
      "metadata": {
        "id": "sxQVDm4-s6BX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4ff1692-5b7f-4eed-c61d-c6ab5988e427"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "박진희 , ' 횡령 피고인 ' 행사 MC → ' 닥터 탐정 ' 하차 요구 시위\n",
            " ' SBS 는 공직자 부인 하지 말아야 할 행동 한 박진희 즉각 퇴 출시 켜야 한다 ' 며 ' 사회 고발 드라마 논란 배우 박진희 왠 말 이냐 ' 는 뜻 전 했다 . 박진희 는 지난해 순천 지역 개발 사업 관련 해 횡령 혐의 재판 받고 있는 A 씨 주최 행사 MC 참석 했다 . 의혹 커지자 박진희 소속사 엘리 펀 엔터테인먼트 측은 ' A 씨 일과 박진희 남편 B 판사 는 전혀 연관 되지 않았다 ' 며 ' A 씨 재판 은 4월 시작 됐는데 , 당시 박진희 남편 은 광주 지법 근무 했다 . A 씨 사건 은 형사 재판 박진희 남편 은 민사 담당 이다 ' 고 해명 했다 . 그러면서 ' 문제 있을 만 한 곳 이란 걸 알았으면 당연히 참석 하지 않았을 ' 라며 ' 박진희 는 보통 행사 처럼 MC 보는 정도 생각 하고 갔다 . 사적 인 자리 간 아니다 ' 고 억울함을 전 했다 . 박진희 는 SBS 새 드라마 ' 닥터 탐정 ' 앞두고 .\n",
            "' SBS 는 공직자 부인 하지 말아야 할 행동 한 박진희 즉각 퇴 출시 켜야 한다'며'사회 고발 드라마 논란 배우 박진희 왠 의혹 커지자 박진희 소속사 엘리 펀 엔터테인먼트 측은'A 씨 일과 박진희 남편 B 판사 는 전혀 연관 되지 않았다'며'A 그러면서'문제 있을 만 한 곳 이란 걸 알았으면 당연히 참석 하지 않았을'라며'박진희 는 보통 행사 처럼 MC 보는 정도 생각 하고\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_new_for_answer = pd.read_csv(\"/content/drive/MyDrive/temp_df.csv\")"
      ],
      "metadata": {
        "id": "mRS86H5Is7Xv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class rdass:\n",
        "  def __init__(self,encoder,tokenizer):\n",
        "    self.encoder = encoder\n",
        "    self.tokenizer = tokenizer\n",
        "    self.encoder.eval()\n",
        "  def __call__(self, text = None, label = None, answer = None):\n",
        "    with torch.no_grad():\n",
        "      text_ids = self.tokenizer(text,truncation = True,max_length = 512,return_tensors = 'pt')\n",
        "      label_ids = self.tokenizer(label,return_tensors = 'pt')\n",
        "      answer_ids = self.tokenizer(answer,return_tensors = 'pt')\n",
        "      # print(text_ids['input_ids'].shape,\" \",label_ids['input_ids'].shape,\" \",answer_ids['input_ids'].shape)\n",
        "      vector_text = self.encoder(**text_ids)['last_hidden_state'] # vector_d\n",
        "      vector_label = self.encoder(**label_ids)['last_hidden_state'] # vector_r\n",
        "      vector_answer = self.encoder(**answer_ids)['last_hidden_state'] # vector_p\n",
        "      \n",
        "    return get_score(vector_text[0,0,:],vector_label[0,0,:],vector_answer[0,0,:])"
      ],
      "metadata": {
        "id": "ui4qJPg0s8nd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenzier_for_eval = AutoTokenizer.from_pretrained(\"klue/roberta-small\")\n",
        "model_for_eval = AutoModel.from_pretrained(\"klue/roberta-small\")\n",
        "metric = rdass(model_for_eval,tokenzier_for_eval)"
      ],
      "metadata": {
        "id": "Yq5-6ZTSs-qP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246,
          "referenced_widgets": [
            "27c12e6702304c48bc881ce6d86cfedd",
            "aa89508f78224a8d9b2ab525820021b4",
            "3395363ccd624d7fb7516573b58fed6d",
            "1192f5024d19473c8ec884f66e4fb0da",
            "3f37563126604e2fa7fe7dde8754dd39",
            "bda286eccf334dffac9fcd43599f3d70",
            "41ca4cc3e7d94a5ab11a0f878d6863c0",
            "4cbd8a78490640e8a85e6f97072986a0",
            "354601429e864562b15c4d6fc076794e",
            "6ab01d3d62124074ae7622824723c1f3",
            "84c8bef952da46d3b79559a591062bb2",
            "92f0a61cb84340aab1ec58c23d12a63e",
            "96755a28768347308d94cb38b2c43fbd",
            "5b1c99b973bc4eaead9995a0109f8502",
            "271024e2e6124f05b3a9d763ec200331",
            "3f68d91fcc674a3ba48b6c8ab0646a38",
            "b34567df09c149fc9418215944cb2a73",
            "8569bc15c37f42498d22cd87f2e6d39f",
            "cce7ca8acd704173bbab257788864b28",
            "557f5fe53c4346e0afce160f651947f7",
            "76e0c1f7b7d140a5a9e11b8312962f4f",
            "44110f8d4f6b48bbafc64d2a9ef6134f",
            "83982aea703e4824b67a07392c10bd49",
            "aff29cfc58c843c689ae6dc4d4e6a954",
            "f192ca7924e6472584f48d90e68a6ffb",
            "08032619e8d7424da27d3f3f2463edf5",
            "fdffb23f7fa6489c923dbba953f915e7",
            "08c5f85a60754a2d9355292b8453c3d4",
            "2d61e46eac3e4b69abbd1398d9196ad1",
            "4f1dac26d6584af8a4a25aba6592637c",
            "185fe653768f47179ca2c0b53996fcd3",
            "9996ac88473f43af8c2a741cd8169d3b",
            "7e4a4ee146144ec6ac7ea6de6c230f2a",
            "2ac65f8e69f74cb1a38e65ca47c1d91e",
            "cd2c5a56288c4ccfafafa269f7956c9c",
            "1111a0c1490c4c559bf94b34e1391ae4",
            "d23b7efa597949ec9cd7f41dc0f6b942",
            "6a9e2983d6f340d398848d1fa51982e9",
            "c752a5a37f204a31ab8f960ce810ed72",
            "580a05e98ed048b397be96840050fc3b",
            "5181b96cd20b43cab7e7d66f157daeb2",
            "c21c68da638a4a678903d819433a5e4c",
            "3aba0867f33e4c4ca8662e46afcf272d",
            "c99c428b2fc9446389bf298d3e481c7e",
            "25e5fb460cf44c319f3b6b21ae13d2c9",
            "a4975bcc02184ed99036b539bbeb74fa",
            "8282563d0cb34dffad962f70f25b0282",
            "0d57f32ad0b84401b1dc3a1545cb28f0",
            "47c1d8d62a1140b1a9094c26d68740e1",
            "6e0c430b6c1b4a2aab8885a09c9052aa",
            "173eaeeb934e4239b637b69d5e9b7c8e",
            "e63d3e0d2a544499bf93de03a0e632e1",
            "6e6df246896c43f5a217d5081824d98b",
            "8a8ca2ee00944c328315477924d569e8",
            "d44cd6e09b614d018891a220b824f144",
            "889dd441781e43338eebb6f2df6abda3",
            "71314f261f0b4585ba22eadf046f0f86",
            "dcc8354e36bc45d28d2963b286b212d6",
            "6bfd9b0215e5463a88f92210166c0f36",
            "0e2c12a376c3441f9d109ff04c2e6700",
            "47fe9495791d42faa3303827937362c9",
            "0c75df9ab030491dbe6454cea87ad0bf",
            "b8484c50855f479d8101f7bbc4dcc3e5",
            "357472a371c1409c98b79edca7c8126f",
            "a4d8097a6931489b9326cd0a28500181",
            "2bc96adfd5484b95a5f7464b7d1cb53c"
          ]
        },
        "outputId": "c663643b-6787-4600-eb03-102d9108a1fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/545 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "27c12e6702304c48bc881ce6d86cfedd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/248k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "92f0a61cb84340aab1ec58c23d12a63e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/752k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "83982aea703e4824b67a07392c10bd49"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/173 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2ac65f8e69f74cb1a38e65ca47c1d91e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/375 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "25e5fb460cf44c319f3b6b21ae13d2c9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/273M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "889dd441781e43338eebb6f2df6abda3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-small and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "metric = rdass(model_for_eval,tokenzier_for_eval)"
      ],
      "metadata": {
        "id": "T4i6hqyQtAJL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_new_for_answer['model_answer_sentence'])"
      ],
      "metadata": {
        "id": "QzDhqWHdtBVF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb239b38-3199-4af0-f672-f0cf97ab4c0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0        문 대통령 은 \" 5 G 분야 융합 되면, 정보통 신 산업 넘어 자동차, 드론 ( ...\n",
            "1        손 대표 는 회의 주재 \" 의원 이나 지역 위원장, 당원 선거 대해 불안하게 생각 ...\n",
            "2        문재인 대통령, 홍 남기 부총리 겸 기획재정부 장관 유영민 과학기술 정보통신부 장관...\n",
            "3        박 시장 은 \" 피 흘리고 서 있는 게 안 보이시나요. 상대로 많은 사람 층 고를 ...\n",
            "4        SK 알파벳 은 신규 투자 는 지주회사 전담 하고, 자회사 는 본업 에만 충실할 수...\n",
            "                               ...                        \n",
            "19759    김영태 KCFT 대표 는 \" KCFT 도전 기술 력 만나 초 극 박 세계 최 장 길...\n",
            "19760    ' 신한 BNPP 글로벌 단기채 권 펀드'는 시장 환경 투자자 니 즈 반영 하여 설...\n",
            "19761    한편 삼육대 는 개교 113 주년 터전 이전 70 주년 맞아 한 주 다양한 기념 사...\n",
            "19762    한국 학자 로는 고려대 최호철 BK 21 플러스 한국어 문학사 업단 단장, 승철 교...\n",
            "19763    서울시 경기도 2020년 모든 마을 버스 공공 와이파이 설치 할 계획 인데, 이보 ...\n",
            "Name: model_answer_sentence, Length: 19764, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_new_for_answer['score'] = df_new_for_answer['text']\n",
        "for i in tqdm(range(len(df_new_for_answer))):\n",
        "    if df_new_for_answer['model_answer_sentence'].iloc[i] == \"error_sentence\": continue\n",
        "    \n",
        "    else:\n",
        "        df_new_for_answer['score'].iloc[i] = metric(\n",
        "                                                text = df_new_for_answer['text'].iloc[i],\n",
        "                                                label = df_new_for_answer['TITLE'].iloc[i], \n",
        "                                                answer = df_new_for_answer['model_answer_sentence'].iloc[i]\n",
        "    )"
      ],
      "metadata": {
        "id": "2CJDiZygtDiy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c19be59e-c7e3-4259-8183-9ec5e6e5a118"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/19764 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py:1732: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self._setitem_single_block(indexer, value, name)\n",
            "100%|██████████| 19764/19764 [1:15:30<00:00,  4.36it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_new_for_answer.head(20)"
      ],
      "metadata": {
        "id": "erWxCpxVtFlv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7c4b35ab-8f6b-4d83-96fc-8118d0b2af9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    Unnamed: 0                                              TITLE  \\\n",
              "0            0                   文 대통령 \" 5 G 는 4 차 산업혁명 시대 고속도로 \"   \n",
              "1            1              \" 손학규 물러나라 \"... 바른계 , 최고 위 회의 ' 보이콧 '   \n",
              "2            2              \" 한 장소 처럼 \" ... 5 G 서울 · 부산 · 광주 원격협연   \n",
              "3            3  \" 이웃 도 모르는데 , 게 서울 미래 냐 \"...' 고층 재개발 요구 ' 작심 비...   \n",
              "4            4          \" SK · 알파벳 벤치마킹 해야 \"... KB 운용 , KMH 주주 서한   \n",
              "5            5       ' 페이크 ' 김지훈 \" 욕 먹을 각오 \"... PD \" 소송 기다리는 느낌 \"   \n",
              "6            6          공기업 실적 나빠지자 無 배당 ... 배당금 수입 줄어 정부 ' 부메랑 '   \n",
              "7            7                베트남 펀드 홀로 뭉칫돈 ... 올해 증시 전망 도 ' 맑음 '   \n",
              "8            8                          美 서 불어온 훈풍 ... 잘나가는 평화 정공   \n",
              "9            9                금감원 , 증권사 부동산 금융 · 발행 어음 사업 꼼꼼히 살핀다   \n",
              "10          10                               베스트 證 , 내달 900억 유상증자   \n",
              "11          11                         \" 민노총 , 국회 폭력 주 동자 엄정 수사 \"   \n",
              "12          12  법 알못 ｜ 마약 투약 황하나 \" 잠든 사이 강제 투약 당해 \"... 사실이라면 처...   \n",
              "13          13                    \" 군대 생활 은 만의 브랜드 만들 수 있는 기회 죠 \"   \n",
              "14          14                   법원 \" 한시 적 업무 프리랜서 개발자 는 근로자 아냐 \"   \n",
              "15          15                   진화 된 음성인식 기술 ...' 놈 목소리 ' 꼼짝 마 !   \n",
              "16          16  서울 서 전시회 는 세계 적 디자이너 폴 스미스 \" 영감 · 개성 표 출하 는 법 ...   \n",
              "17          17                               법관 대표 회의 의장 ' 법 ' 출신   \n",
              "18          18       ' 아이돌 룸 ' 헨리 X 볼 빨간 사춘기 , 음악 천재 ' 귀 호강 ' 콜라보   \n",
              "19          19                               女 골프 ' 깃대 퍼팅 ' 전성 시대   \n",
              "\n",
              "                                                 text  \\\n",
              "0    문 대통령 은 \" 5 G 분야 융합 되면 , 정보통 신 산업 넘어 자동차 , 드론...   \n",
              "1    손 대표 는 회의 주재 \" 의원 이나 지역 위원장 , 당원 선거 대해 불안하게 생...   \n",
              "2    공연 은 5 G 이동통신 실시간 전송 기술 활용 해 서울 부산 , 광주 동시 하는...   \n",
              "3    박 시장 은 \" 피 흘리고 서 있는 게 안 보이시나요 . 상대로 많은 사람 층 고...   \n",
              "4    SK 알파벳 은 신규 투자 는 지주회사 전담 하고 , 자회사 는 본업 에만 충실할...   \n",
              "5    프리랜서 기자 김웅 씨 손석희 대표이사 폭행 당했다고 주장 하며 시작 된 논란 은...   \n",
              "6    배당 가능 공기업 배당 성향 은 31.3% , 당초 올해 중기 목표 ( 37.0%...   \n",
              "7    베트남 펀드 순 자산 규모 는 2조 856억원 불어 처음 2조원 대를 돌파 했다 ...   \n",
              "8    현대차 팰리세이드 , 기아차 텔루 라이드 신규 스포츠 유틸리티 차량 ( SUV )...   \n",
              "9    금감원 은 지난달 PF 보증 규모 상위 15 개 증권사 대상 부동산 금융 실태 조...   \n",
              "10   베스트 투자 증권 은 증자 통해 턱 없이 낮은 소액 주주 지 분율 높여 유통 주식...   \n",
              "11   전 국민 주 노동조합 총 연맹 은 지난 3일 국회 앞 대규모 결의 대회 열었다 ....   \n",
              "12   마약 투약 한 사실 은 인정 A 씨 잠든 사이 강제 투약 했다는 주장 도 했다 ....   \n",
              "13   는 2000만원 가치 산정 기준 은 ' 비밀 ' 라며 멋쩍 게 웃었다 . 군 복무...   \n",
              "14   김씨 는 2017년 7월 소프트웨어 개발 업체 구두 계약 체결 하고 프로그램 개발...   \n",
              "15   검찰 관계자 는 \" 수사 과정 입수 한 녹음 파일 대해 목소리 아니라고 발뺌 하는...   \n",
              "16   스미스 는 날 기자간담회 \" 10 대 , 대학생 디자이너 꿈꾸는 학생 많이 찾아와...   \n",
              "17   김 대법원 장 은 \" 재판 결과 일부 제기 하는 법관 개인 신상 이나 성향 대한 ...   \n",
              "18   최근 진행 된 ' 아이돌 룸 ' 녹화 헨리 는 볼 빨간 사춘기 와의 인연 깜짝 공...   \n",
              "19   고 진영 은 짧든 , 길든 대다수 퍼팅 깃대 꽂은 채 한다 . 고 진영 은 깃대 ...   \n",
              "\n",
              "                                model_answer_sentence  \\\n",
              "0   문 대통령 은 \" 5 G 분야 융합 되면, 정보통 신 산업 넘어 자동차, 드론 ( ...   \n",
              "1   손 대표 는 회의 주재 \" 의원 이나 지역 위원장, 당원 선거 대해 불안하게 생각 ...   \n",
              "2   문재인 대통령, 홍 남기 부총리 겸 기획재정부 장관 유영민 과학기술 정보통신부 장관...   \n",
              "3   박 시장 은 \" 피 흘리고 서 있는 게 안 보이시나요. 상대로 많은 사람 층 고를 ...   \n",
              "4   SK 알파벳 은 신규 투자 는 지주회사 전담 하고, 자회사 는 본업 에만 충실할 수...   \n",
              "5   는'당시 사건 터지고 많은 매체 다뤘다. 타 방송사 사장 이라 주 함 은 있었지만 ...   \n",
              "6   정부 출자 기관 중 에는 대우조선 해양 지 분법 평가 이익 ( 2조원 ) 본 산업 ...   \n",
              "7   수익률 도 반등 하고. 작년 900 선 아래 밑 돌던 베트남 VN 30 지수 는 올...   \n",
              "8   현대차 노조 도 지난 1일 팰리세이드 증산 합의 해 부품 주문 더 늘 이란 관측 나...   \n",
              "9   금감원 은 지난달 PF 보증 규모 상위 15 개 증권사 대상 부동산 금융 실태 조사...   \n",
              "10  증권사 는 낮은 소액 주주 지 분율 인해 관리종목 지정 될 위기 놓여. 베스트 투자...   \n",
              "11  민 청장 은 \" 기자 폭행 한 2 건 대해 서는 강력 2 개 팀 전담 팀 투입 해 ...   \n",
              "12  수사 A 씨 외 연예인 연루 된 사실 드러나면 황하나 발 ( 發 ) 마약 사건 은 ...   \n",
              "13  군 복무 기간 은 지나 온 되돌아보고 미래 준비 하는'브레이크 타임 '. 손씨 는 ...   \n",
              "14  법원 은 김씨 근로자 아니라고 봤다. 이어 \" 김씨 회사 근로 계약 체결 하고자 했...   \n",
              "15  검찰 관계자 는 \" 수사 과정 입수 한 녹음 파일 대해 목소리 아니라고 발뺌 하는 ...   \n",
              "16  1970년 영국 노팅엄 9 m2 크기 공 방 시작 한 스미스 는 지난해 ( 2017...   \n",
              "17  날 회의 에서는 전국 급 법원 대표 판사 총 125 명 가운데 120 명 참석 해 ...   \n",
              "18  두 팀 은'음악 천재'다운 능력 한껏 뽐낼 수 있는'즉흥 창작 미션'도전 했다. 헨...   \n",
              "19  지난 7일 끝난 한국 여자 프로 골프 ( KLPGA ) 투어 개막전 롯데 렌터카 오...   \n",
              "\n",
              "                                                score  \n",
              "0   <built-in method item of Tensor object at 0x7f...  \n",
              "1   <built-in method item of Tensor object at 0x7f...  \n",
              "2   <built-in method item of Tensor object at 0x7f...  \n",
              "3   <built-in method item of Tensor object at 0x7f...  \n",
              "4   <built-in method item of Tensor object at 0x7f...  \n",
              "5   <built-in method item of Tensor object at 0x7f...  \n",
              "6   <built-in method item of Tensor object at 0x7f...  \n",
              "7   <built-in method item of Tensor object at 0x7f...  \n",
              "8   <built-in method item of Tensor object at 0x7f...  \n",
              "9   <built-in method item of Tensor object at 0x7f...  \n",
              "10  <built-in method item of Tensor object at 0x7f...  \n",
              "11  <built-in method item of Tensor object at 0x7f...  \n",
              "12  <built-in method item of Tensor object at 0x7f...  \n",
              "13  <built-in method item of Tensor object at 0x7f...  \n",
              "14  <built-in method item of Tensor object at 0x7f...  \n",
              "15  <built-in method item of Tensor object at 0x7f...  \n",
              "16  <built-in method item of Tensor object at 0x7f...  \n",
              "17  <built-in method item of Tensor object at 0x7f...  \n",
              "18  <built-in method item of Tensor object at 0x7f...  \n",
              "19  <built-in method item of Tensor object at 0x7f...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0660d141-9f87-4e8d-b409-e96b1c8ca3b1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>TITLE</th>\n",
              "      <th>text</th>\n",
              "      <th>model_answer_sentence</th>\n",
              "      <th>score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>文 대통령 \" 5 G 는 4 차 산업혁명 시대 고속도로 \"</td>\n",
              "      <td>문 대통령 은 \" 5 G 분야 융합 되면 , 정보통 신 산업 넘어 자동차 , 드론...</td>\n",
              "      <td>문 대통령 은 \" 5 G 분야 융합 되면, 정보통 신 산업 넘어 자동차, 드론 ( ...</td>\n",
              "      <td>&lt;built-in method item of Tensor object at 0x7f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>\" 손학규 물러나라 \"... 바른계 , 최고 위 회의 ' 보이콧 '</td>\n",
              "      <td>손 대표 는 회의 주재 \" 의원 이나 지역 위원장 , 당원 선거 대해 불안하게 생...</td>\n",
              "      <td>손 대표 는 회의 주재 \" 의원 이나 지역 위원장, 당원 선거 대해 불안하게 생각 ...</td>\n",
              "      <td>&lt;built-in method item of Tensor object at 0x7f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>\" 한 장소 처럼 \" ... 5 G 서울 · 부산 · 광주 원격협연</td>\n",
              "      <td>공연 은 5 G 이동통신 실시간 전송 기술 활용 해 서울 부산 , 광주 동시 하는...</td>\n",
              "      <td>문재인 대통령, 홍 남기 부총리 겸 기획재정부 장관 유영민 과학기술 정보통신부 장관...</td>\n",
              "      <td>&lt;built-in method item of Tensor object at 0x7f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>\" 이웃 도 모르는데 , 게 서울 미래 냐 \"...' 고층 재개발 요구 ' 작심 비...</td>\n",
              "      <td>박 시장 은 \" 피 흘리고 서 있는 게 안 보이시나요 . 상대로 많은 사람 층 고...</td>\n",
              "      <td>박 시장 은 \" 피 흘리고 서 있는 게 안 보이시나요. 상대로 많은 사람 층 고를 ...</td>\n",
              "      <td>&lt;built-in method item of Tensor object at 0x7f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>\" SK · 알파벳 벤치마킹 해야 \"... KB 운용 , KMH 주주 서한</td>\n",
              "      <td>SK 알파벳 은 신규 투자 는 지주회사 전담 하고 , 자회사 는 본업 에만 충실할...</td>\n",
              "      <td>SK 알파벳 은 신규 투자 는 지주회사 전담 하고, 자회사 는 본업 에만 충실할 수...</td>\n",
              "      <td>&lt;built-in method item of Tensor object at 0x7f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>' 페이크 ' 김지훈 \" 욕 먹을 각오 \"... PD \" 소송 기다리는 느낌 \"</td>\n",
              "      <td>프리랜서 기자 김웅 씨 손석희 대표이사 폭행 당했다고 주장 하며 시작 된 논란 은...</td>\n",
              "      <td>는'당시 사건 터지고 많은 매체 다뤘다. 타 방송사 사장 이라 주 함 은 있었지만 ...</td>\n",
              "      <td>&lt;built-in method item of Tensor object at 0x7f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>공기업 실적 나빠지자 無 배당 ... 배당금 수입 줄어 정부 ' 부메랑 '</td>\n",
              "      <td>배당 가능 공기업 배당 성향 은 31.3% , 당초 올해 중기 목표 ( 37.0%...</td>\n",
              "      <td>정부 출자 기관 중 에는 대우조선 해양 지 분법 평가 이익 ( 2조원 ) 본 산업 ...</td>\n",
              "      <td>&lt;built-in method item of Tensor object at 0x7f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>베트남 펀드 홀로 뭉칫돈 ... 올해 증시 전망 도 ' 맑음 '</td>\n",
              "      <td>베트남 펀드 순 자산 규모 는 2조 856억원 불어 처음 2조원 대를 돌파 했다 ...</td>\n",
              "      <td>수익률 도 반등 하고. 작년 900 선 아래 밑 돌던 베트남 VN 30 지수 는 올...</td>\n",
              "      <td>&lt;built-in method item of Tensor object at 0x7f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>美 서 불어온 훈풍 ... 잘나가는 평화 정공</td>\n",
              "      <td>현대차 팰리세이드 , 기아차 텔루 라이드 신규 스포츠 유틸리티 차량 ( SUV )...</td>\n",
              "      <td>현대차 노조 도 지난 1일 팰리세이드 증산 합의 해 부품 주문 더 늘 이란 관측 나...</td>\n",
              "      <td>&lt;built-in method item of Tensor object at 0x7f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>금감원 , 증권사 부동산 금융 · 발행 어음 사업 꼼꼼히 살핀다</td>\n",
              "      <td>금감원 은 지난달 PF 보증 규모 상위 15 개 증권사 대상 부동산 금융 실태 조...</td>\n",
              "      <td>금감원 은 지난달 PF 보증 규모 상위 15 개 증권사 대상 부동산 금융 실태 조사...</td>\n",
              "      <td>&lt;built-in method item of Tensor object at 0x7f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>10</td>\n",
              "      <td>베스트 證 , 내달 900억 유상증자</td>\n",
              "      <td>베스트 투자 증권 은 증자 통해 턱 없이 낮은 소액 주주 지 분율 높여 유통 주식...</td>\n",
              "      <td>증권사 는 낮은 소액 주주 지 분율 인해 관리종목 지정 될 위기 놓여. 베스트 투자...</td>\n",
              "      <td>&lt;built-in method item of Tensor object at 0x7f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>11</td>\n",
              "      <td>\" 민노총 , 국회 폭력 주 동자 엄정 수사 \"</td>\n",
              "      <td>전 국민 주 노동조합 총 연맹 은 지난 3일 국회 앞 대규모 결의 대회 열었다 ....</td>\n",
              "      <td>민 청장 은 \" 기자 폭행 한 2 건 대해 서는 강력 2 개 팀 전담 팀 투입 해 ...</td>\n",
              "      <td>&lt;built-in method item of Tensor object at 0x7f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>12</td>\n",
              "      <td>법 알못 ｜ 마약 투약 황하나 \" 잠든 사이 강제 투약 당해 \"... 사실이라면 처...</td>\n",
              "      <td>마약 투약 한 사실 은 인정 A 씨 잠든 사이 강제 투약 했다는 주장 도 했다 ....</td>\n",
              "      <td>수사 A 씨 외 연예인 연루 된 사실 드러나면 황하나 발 ( 發 ) 마약 사건 은 ...</td>\n",
              "      <td>&lt;built-in method item of Tensor object at 0x7f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>13</td>\n",
              "      <td>\" 군대 생활 은 만의 브랜드 만들 수 있는 기회 죠 \"</td>\n",
              "      <td>는 2000만원 가치 산정 기준 은 ' 비밀 ' 라며 멋쩍 게 웃었다 . 군 복무...</td>\n",
              "      <td>군 복무 기간 은 지나 온 되돌아보고 미래 준비 하는'브레이크 타임 '. 손씨 는 ...</td>\n",
              "      <td>&lt;built-in method item of Tensor object at 0x7f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>14</td>\n",
              "      <td>법원 \" 한시 적 업무 프리랜서 개발자 는 근로자 아냐 \"</td>\n",
              "      <td>김씨 는 2017년 7월 소프트웨어 개발 업체 구두 계약 체결 하고 프로그램 개발...</td>\n",
              "      <td>법원 은 김씨 근로자 아니라고 봤다. 이어 \" 김씨 회사 근로 계약 체결 하고자 했...</td>\n",
              "      <td>&lt;built-in method item of Tensor object at 0x7f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>15</td>\n",
              "      <td>진화 된 음성인식 기술 ...' 놈 목소리 ' 꼼짝 마 !</td>\n",
              "      <td>검찰 관계자 는 \" 수사 과정 입수 한 녹음 파일 대해 목소리 아니라고 발뺌 하는...</td>\n",
              "      <td>검찰 관계자 는 \" 수사 과정 입수 한 녹음 파일 대해 목소리 아니라고 발뺌 하는 ...</td>\n",
              "      <td>&lt;built-in method item of Tensor object at 0x7f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>16</td>\n",
              "      <td>서울 서 전시회 는 세계 적 디자이너 폴 스미스 \" 영감 · 개성 표 출하 는 법 ...</td>\n",
              "      <td>스미스 는 날 기자간담회 \" 10 대 , 대학생 디자이너 꿈꾸는 학생 많이 찾아와...</td>\n",
              "      <td>1970년 영국 노팅엄 9 m2 크기 공 방 시작 한 스미스 는 지난해 ( 2017...</td>\n",
              "      <td>&lt;built-in method item of Tensor object at 0x7f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>17</td>\n",
              "      <td>법관 대표 회의 의장 ' 법 ' 출신</td>\n",
              "      <td>김 대법원 장 은 \" 재판 결과 일부 제기 하는 법관 개인 신상 이나 성향 대한 ...</td>\n",
              "      <td>날 회의 에서는 전국 급 법원 대표 판사 총 125 명 가운데 120 명 참석 해 ...</td>\n",
              "      <td>&lt;built-in method item of Tensor object at 0x7f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>18</td>\n",
              "      <td>' 아이돌 룸 ' 헨리 X 볼 빨간 사춘기 , 음악 천재 ' 귀 호강 ' 콜라보</td>\n",
              "      <td>최근 진행 된 ' 아이돌 룸 ' 녹화 헨리 는 볼 빨간 사춘기 와의 인연 깜짝 공...</td>\n",
              "      <td>두 팀 은'음악 천재'다운 능력 한껏 뽐낼 수 있는'즉흥 창작 미션'도전 했다. 헨...</td>\n",
              "      <td>&lt;built-in method item of Tensor object at 0x7f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>19</td>\n",
              "      <td>女 골프 ' 깃대 퍼팅 ' 전성 시대</td>\n",
              "      <td>고 진영 은 짧든 , 길든 대다수 퍼팅 깃대 꽂은 채 한다 . 고 진영 은 깃대 ...</td>\n",
              "      <td>지난 7일 끝난 한국 여자 프로 골프 ( KLPGA ) 투어 개막전 롯데 렌터카 오...</td>\n",
              "      <td>&lt;built-in method item of Tensor object at 0x7f...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0660d141-9f87-4e8d-b409-e96b1c8ca3b1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0660d141-9f87-4e8d-b409-e96b1c8ca3b1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0660d141-9f87-4e8d-b409-e96b1c8ca3b1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_new_for_answer['score_temp'] = df_new_for_answer['score'] \n",
        "for i in tqdm(range(len(df_new_for_answer)-1,0,-1)):\n",
        "    if type(df_new_for_answer['score'].iloc[i]) == type(\"string\"): continue\n",
        "    else:\n",
        "        df_new_for_answer['score_temp'].iloc[i] = df_new_for_answer['score'].iloc[i].item()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hvLiCBQS6_Q0",
        "outputId": "b8a85efe-e267-4d99-f648-73d16c96c554"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/19763 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py:1732: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self._setitem_single_block(indexer, value, name)\n",
            "100%|██████████| 19763/19763 [00:09<00:00, 2122.56it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_new_for_answer['score'] = df_new_for_answer['score_temp'] "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GwyLm8OG7wKy",
        "outputId": "94111909-30c3-4e1e-97fb-6d77f9cdcc65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0     tensor(0.9494)\n",
              "1           0.925497\n",
              "2           0.925301\n",
              "3           0.914548\n",
              "4           0.922859\n",
              "5           0.919173\n",
              "6           0.929878\n",
              "7           0.939474\n",
              "8            0.92415\n",
              "9           0.951694\n",
              "10          0.927527\n",
              "11          0.919671\n",
              "12          0.924827\n",
              "13          0.956905\n",
              "14           0.94025\n",
              "15           0.94002\n",
              "16          0.923289\n",
              "17          0.935444\n",
              "18          0.934781\n",
              "19          0.910123\n",
              "Name: score_temp, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_tokenized_val_new.to_csv(\"/content/drive/MyDrive/Summary_task/result.csv\",mode = 'w')"
      ],
      "metadata": {
        "id": "MqlWbgITTZ4r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_tokenized_val_new = pd.read_csv(\"/content/drive/MyDrive/Summary_task/result_1.csv\")"
      ],
      "metadata": {
        "id": "c7mKdWRErOHJ"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_tokenized_val_new.head(20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "x5tv1Ba9rRfm",
        "outputId": "56d4c454-d16e-4bba-9aa6-ca46c0d5bf02"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    Unnamed: 0  Unnamed: 0.1  \\\n",
              "0            0             0   \n",
              "1            1             1   \n",
              "2            2             2   \n",
              "3            3             3   \n",
              "4            4             4   \n",
              "5            5             5   \n",
              "6            6             6   \n",
              "7            7             7   \n",
              "8            8             8   \n",
              "9            9             9   \n",
              "10          10            10   \n",
              "11          11            11   \n",
              "12          12            12   \n",
              "13          13            13   \n",
              "14          14            14   \n",
              "15          15            15   \n",
              "16          16            16   \n",
              "17          17            17   \n",
              "18          18            18   \n",
              "19          19            19   \n",
              "\n",
              "                                                TITLE  \\\n",
              "0                    文 대통령 \" 5 G 는 4 차 산업혁명 시대 고속도로 \"   \n",
              "1               \" 손학규 물러나라 \"... 바른계 , 최고 위 회의 ' 보이콧 '   \n",
              "2               \" 한 장소 처럼 \" ... 5 G 서울 · 부산 · 광주 원격협연   \n",
              "3   \" 이웃 도 모르는데 , 게 서울 미래 냐 \"...' 고층 재개발 요구 ' 작심 비...   \n",
              "4           \" SK · 알파벳 벤치마킹 해야 \"... KB 운용 , KMH 주주 서한   \n",
              "5        ' 페이크 ' 김지훈 \" 욕 먹을 각오 \"... PD \" 소송 기다리는 느낌 \"   \n",
              "6           공기업 실적 나빠지자 無 배당 ... 배당금 수입 줄어 정부 ' 부메랑 '   \n",
              "7                 베트남 펀드 홀로 뭉칫돈 ... 올해 증시 전망 도 ' 맑음 '   \n",
              "8                           美 서 불어온 훈풍 ... 잘나가는 평화 정공   \n",
              "9                 금감원 , 증권사 부동산 금융 · 발행 어음 사업 꼼꼼히 살핀다   \n",
              "10                               베스트 證 , 내달 900억 유상증자   \n",
              "11                         \" 민노총 , 국회 폭력 주 동자 엄정 수사 \"   \n",
              "12  법 알못 ｜ 마약 투약 황하나 \" 잠든 사이 강제 투약 당해 \"... 사실이라면 처...   \n",
              "13                    \" 군대 생활 은 만의 브랜드 만들 수 있는 기회 죠 \"   \n",
              "14                   법원 \" 한시 적 업무 프리랜서 개발자 는 근로자 아냐 \"   \n",
              "15                   진화 된 음성인식 기술 ...' 놈 목소리 ' 꼼짝 마 !   \n",
              "16  서울 서 전시회 는 세계 적 디자이너 폴 스미스 \" 영감 · 개성 표 출하 는 법 ...   \n",
              "17                               법관 대표 회의 의장 ' 법 ' 출신   \n",
              "18       ' 아이돌 룸 ' 헨리 X 볼 빨간 사춘기 , 음악 천재 ' 귀 호강 ' 콜라보   \n",
              "19                               女 골프 ' 깃대 퍼팅 ' 전성 시대   \n",
              "\n",
              "                                                 text  \\\n",
              "0    문 대통령 은 \" 5 G 분야 융합 되면 , 정보통 신 산업 넘어 자동차 , 드론...   \n",
              "1    손 대표 는 회의 주재 \" 의원 이나 지역 위원장 , 당원 선거 대해 불안하게 생...   \n",
              "2    공연 은 5 G 이동통신 실시간 전송 기술 활용 해 서울 부산 , 광주 동시 하는...   \n",
              "3    박 시장 은 \" 피 흘리고 서 있는 게 안 보이시나요 . 상대로 많은 사람 층 고...   \n",
              "4    SK 알파벳 은 신규 투자 는 지주회사 전담 하고 , 자회사 는 본업 에만 충실할...   \n",
              "5    프리랜서 기자 김웅 씨 손석희 대표이사 폭행 당했다고 주장 하며 시작 된 논란 은...   \n",
              "6    배당 가능 공기업 배당 성향 은 31.3% , 당초 올해 중기 목표 ( 37.0%...   \n",
              "7    베트남 펀드 순 자산 규모 는 2조 856억원 불어 처음 2조원 대를 돌파 했다 ...   \n",
              "8    현대차 팰리세이드 , 기아차 텔루 라이드 신규 스포츠 유틸리티 차량 ( SUV )...   \n",
              "9    금감원 은 지난달 PF 보증 규모 상위 15 개 증권사 대상 부동산 금융 실태 조...   \n",
              "10   베스트 투자 증권 은 증자 통해 턱 없이 낮은 소액 주주 지 분율 높여 유통 주식...   \n",
              "11   전 국민 주 노동조합 총 연맹 은 지난 3일 국회 앞 대규모 결의 대회 열었다 ....   \n",
              "12   마약 투약 한 사실 은 인정 A 씨 잠든 사이 강제 투약 했다는 주장 도 했다 ....   \n",
              "13   는 2000만원 가치 산정 기준 은 ' 비밀 ' 라며 멋쩍 게 웃었다 . 군 복무...   \n",
              "14   김씨 는 2017년 7월 소프트웨어 개발 업체 구두 계약 체결 하고 프로그램 개발...   \n",
              "15   검찰 관계자 는 \" 수사 과정 입수 한 녹음 파일 대해 목소리 아니라고 발뺌 하는...   \n",
              "16   스미스 는 날 기자간담회 \" 10 대 , 대학생 디자이너 꿈꾸는 학생 많이 찾아와...   \n",
              "17   김 대법원 장 은 \" 재판 결과 일부 제기 하는 법관 개인 신상 이나 성향 대한 ...   \n",
              "18   최근 진행 된 ' 아이돌 룸 ' 녹화 헨리 는 볼 빨간 사춘기 와의 인연 깜짝 공...   \n",
              "19   고 진영 은 짧든 , 길든 대다수 퍼팅 깃대 꽂은 채 한다 . 고 진영 은 깃대 ...   \n",
              "\n",
              "                                model_answer_sentence               score  \\\n",
              "0   문 대통령 은 \" 5 G 분야 융합 되면, 정보통 신 산업 넘어 자동차, 드론 ( ...      tensor(0.9494)   \n",
              "1   손 대표 는 회의 주재 \" 의원 이나 지역 위원장, 당원 선거 대해 불안하게 생각 ...  0.9254969358444214   \n",
              "2   문재인 대통령, 홍 남기 부총리 겸 기획재정부 장관 유영민 과학기술 정보통신부 장관...  0.9253007173538208   \n",
              "3   박 시장 은 \" 피 흘리고 서 있는 게 안 보이시나요. 상대로 많은 사람 층 고를 ...  0.9145475625991821   \n",
              "4   SK 알파벳 은 신규 투자 는 지주회사 전담 하고, 자회사 는 본업 에만 충실할 수...  0.9228593111038208   \n",
              "5   는'당시 사건 터지고 많은 매체 다뤘다. 타 방송사 사장 이라 주 함 은 있었지만 ...  0.9191728830337524   \n",
              "6   정부 출자 기관 중 에는 대우조선 해양 지 분법 평가 이익 ( 2조원 ) 본 산업 ...   0.929878294467926   \n",
              "7   수익률 도 반등 하고. 작년 900 선 아래 밑 돌던 베트남 VN 30 지수 는 올...  0.9394742250442505   \n",
              "8   현대차 노조 도 지난 1일 팰리세이드 증산 합의 해 부품 주문 더 늘 이란 관측 나...  0.9241498708724976   \n",
              "9   금감원 은 지난달 PF 보증 규모 상위 15 개 증권사 대상 부동산 금융 실태 조사...  0.9516940116882324   \n",
              "10  증권사 는 낮은 소액 주주 지 분율 인해 관리종목 지정 될 위기 놓여. 베스트 투자...  0.9275273084640503   \n",
              "11  민 청장 은 \" 기자 폭행 한 2 건 대해 서는 강력 2 개 팀 전담 팀 투입 해 ...  0.9196704626083374   \n",
              "12  수사 A 씨 외 연예인 연루 된 사실 드러나면 황하나 발 ( 發 ) 마약 사건 은 ...  0.9248272180557251   \n",
              "13  군 복무 기간 은 지나 온 되돌아보고 미래 준비 하는'브레이크 타임 '. 손씨 는 ...  0.9569053649902344   \n",
              "14  법원 은 김씨 근로자 아니라고 봤다. 이어 \" 김씨 회사 근로 계약 체결 하고자 했...  0.9402496814727783   \n",
              "15  검찰 관계자 는 \" 수사 과정 입수 한 녹음 파일 대해 목소리 아니라고 발뺌 하는 ...  0.9400198459625244   \n",
              "16  1970년 영국 노팅엄 9 m2 크기 공 방 시작 한 스미스 는 지난해 ( 2017...  0.9232895374298096   \n",
              "17  날 회의 에서는 전국 급 법원 대표 판사 총 125 명 가운데 120 명 참석 해 ...  0.9354445934295654   \n",
              "18  두 팀 은'음악 천재'다운 능력 한껏 뽐낼 수 있는'즉흥 창작 미션'도전 했다. 헨...  0.9347810745239258   \n",
              "19  지난 7일 끝난 한국 여자 프로 골프 ( KLPGA ) 투어 개막전 롯데 렌터카 오...  0.9101230502128601   \n",
              "\n",
              "            score_temp  \n",
              "0       tensor(0.9494)  \n",
              "1   0.9254969358444214  \n",
              "2   0.9253007173538208  \n",
              "3   0.9145475625991821  \n",
              "4   0.9228593111038208  \n",
              "5   0.9191728830337524  \n",
              "6    0.929878294467926  \n",
              "7   0.9394742250442505  \n",
              "8   0.9241498708724976  \n",
              "9   0.9516940116882324  \n",
              "10  0.9275273084640503  \n",
              "11  0.9196704626083374  \n",
              "12  0.9248272180557251  \n",
              "13  0.9569053649902344  \n",
              "14  0.9402496814727783  \n",
              "15  0.9400198459625244  \n",
              "16  0.9232895374298096  \n",
              "17  0.9354445934295654  \n",
              "18  0.9347810745239258  \n",
              "19  0.9101230502128601  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f83b0783-6a58-49a4-ba15-ea206acc0783\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Unnamed: 0.1</th>\n",
              "      <th>TITLE</th>\n",
              "      <th>text</th>\n",
              "      <th>model_answer_sentence</th>\n",
              "      <th>score</th>\n",
              "      <th>score_temp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>文 대통령 \" 5 G 는 4 차 산업혁명 시대 고속도로 \"</td>\n",
              "      <td>문 대통령 은 \" 5 G 분야 융합 되면 , 정보통 신 산업 넘어 자동차 , 드론...</td>\n",
              "      <td>문 대통령 은 \" 5 G 분야 융합 되면, 정보통 신 산업 넘어 자동차, 드론 ( ...</td>\n",
              "      <td>tensor(0.9494)</td>\n",
              "      <td>tensor(0.9494)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>\" 손학규 물러나라 \"... 바른계 , 최고 위 회의 ' 보이콧 '</td>\n",
              "      <td>손 대표 는 회의 주재 \" 의원 이나 지역 위원장 , 당원 선거 대해 불안하게 생...</td>\n",
              "      <td>손 대표 는 회의 주재 \" 의원 이나 지역 위원장, 당원 선거 대해 불안하게 생각 ...</td>\n",
              "      <td>0.9254969358444214</td>\n",
              "      <td>0.9254969358444214</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>\" 한 장소 처럼 \" ... 5 G 서울 · 부산 · 광주 원격협연</td>\n",
              "      <td>공연 은 5 G 이동통신 실시간 전송 기술 활용 해 서울 부산 , 광주 동시 하는...</td>\n",
              "      <td>문재인 대통령, 홍 남기 부총리 겸 기획재정부 장관 유영민 과학기술 정보통신부 장관...</td>\n",
              "      <td>0.9253007173538208</td>\n",
              "      <td>0.9253007173538208</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>\" 이웃 도 모르는데 , 게 서울 미래 냐 \"...' 고층 재개발 요구 ' 작심 비...</td>\n",
              "      <td>박 시장 은 \" 피 흘리고 서 있는 게 안 보이시나요 . 상대로 많은 사람 층 고...</td>\n",
              "      <td>박 시장 은 \" 피 흘리고 서 있는 게 안 보이시나요. 상대로 많은 사람 층 고를 ...</td>\n",
              "      <td>0.9145475625991821</td>\n",
              "      <td>0.9145475625991821</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>\" SK · 알파벳 벤치마킹 해야 \"... KB 운용 , KMH 주주 서한</td>\n",
              "      <td>SK 알파벳 은 신규 투자 는 지주회사 전담 하고 , 자회사 는 본업 에만 충실할...</td>\n",
              "      <td>SK 알파벳 은 신규 투자 는 지주회사 전담 하고, 자회사 는 본업 에만 충실할 수...</td>\n",
              "      <td>0.9228593111038208</td>\n",
              "      <td>0.9228593111038208</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>' 페이크 ' 김지훈 \" 욕 먹을 각오 \"... PD \" 소송 기다리는 느낌 \"</td>\n",
              "      <td>프리랜서 기자 김웅 씨 손석희 대표이사 폭행 당했다고 주장 하며 시작 된 논란 은...</td>\n",
              "      <td>는'당시 사건 터지고 많은 매체 다뤘다. 타 방송사 사장 이라 주 함 은 있었지만 ...</td>\n",
              "      <td>0.9191728830337524</td>\n",
              "      <td>0.9191728830337524</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>공기업 실적 나빠지자 無 배당 ... 배당금 수입 줄어 정부 ' 부메랑 '</td>\n",
              "      <td>배당 가능 공기업 배당 성향 은 31.3% , 당초 올해 중기 목표 ( 37.0%...</td>\n",
              "      <td>정부 출자 기관 중 에는 대우조선 해양 지 분법 평가 이익 ( 2조원 ) 본 산업 ...</td>\n",
              "      <td>0.929878294467926</td>\n",
              "      <td>0.929878294467926</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>베트남 펀드 홀로 뭉칫돈 ... 올해 증시 전망 도 ' 맑음 '</td>\n",
              "      <td>베트남 펀드 순 자산 규모 는 2조 856억원 불어 처음 2조원 대를 돌파 했다 ...</td>\n",
              "      <td>수익률 도 반등 하고. 작년 900 선 아래 밑 돌던 베트남 VN 30 지수 는 올...</td>\n",
              "      <td>0.9394742250442505</td>\n",
              "      <td>0.9394742250442505</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>美 서 불어온 훈풍 ... 잘나가는 평화 정공</td>\n",
              "      <td>현대차 팰리세이드 , 기아차 텔루 라이드 신규 스포츠 유틸리티 차량 ( SUV )...</td>\n",
              "      <td>현대차 노조 도 지난 1일 팰리세이드 증산 합의 해 부품 주문 더 늘 이란 관측 나...</td>\n",
              "      <td>0.9241498708724976</td>\n",
              "      <td>0.9241498708724976</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "      <td>금감원 , 증권사 부동산 금융 · 발행 어음 사업 꼼꼼히 살핀다</td>\n",
              "      <td>금감원 은 지난달 PF 보증 규모 상위 15 개 증권사 대상 부동산 금융 실태 조...</td>\n",
              "      <td>금감원 은 지난달 PF 보증 규모 상위 15 개 증권사 대상 부동산 금융 실태 조사...</td>\n",
              "      <td>0.9516940116882324</td>\n",
              "      <td>0.9516940116882324</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>베스트 證 , 내달 900억 유상증자</td>\n",
              "      <td>베스트 투자 증권 은 증자 통해 턱 없이 낮은 소액 주주 지 분율 높여 유통 주식...</td>\n",
              "      <td>증권사 는 낮은 소액 주주 지 분율 인해 관리종목 지정 될 위기 놓여. 베스트 투자...</td>\n",
              "      <td>0.9275273084640503</td>\n",
              "      <td>0.9275273084640503</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>11</td>\n",
              "      <td>11</td>\n",
              "      <td>\" 민노총 , 국회 폭력 주 동자 엄정 수사 \"</td>\n",
              "      <td>전 국민 주 노동조합 총 연맹 은 지난 3일 국회 앞 대규모 결의 대회 열었다 ....</td>\n",
              "      <td>민 청장 은 \" 기자 폭행 한 2 건 대해 서는 강력 2 개 팀 전담 팀 투입 해 ...</td>\n",
              "      <td>0.9196704626083374</td>\n",
              "      <td>0.9196704626083374</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>12</td>\n",
              "      <td>12</td>\n",
              "      <td>법 알못 ｜ 마약 투약 황하나 \" 잠든 사이 강제 투약 당해 \"... 사실이라면 처...</td>\n",
              "      <td>마약 투약 한 사실 은 인정 A 씨 잠든 사이 강제 투약 했다는 주장 도 했다 ....</td>\n",
              "      <td>수사 A 씨 외 연예인 연루 된 사실 드러나면 황하나 발 ( 發 ) 마약 사건 은 ...</td>\n",
              "      <td>0.9248272180557251</td>\n",
              "      <td>0.9248272180557251</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>13</td>\n",
              "      <td>13</td>\n",
              "      <td>\" 군대 생활 은 만의 브랜드 만들 수 있는 기회 죠 \"</td>\n",
              "      <td>는 2000만원 가치 산정 기준 은 ' 비밀 ' 라며 멋쩍 게 웃었다 . 군 복무...</td>\n",
              "      <td>군 복무 기간 은 지나 온 되돌아보고 미래 준비 하는'브레이크 타임 '. 손씨 는 ...</td>\n",
              "      <td>0.9569053649902344</td>\n",
              "      <td>0.9569053649902344</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>14</td>\n",
              "      <td>14</td>\n",
              "      <td>법원 \" 한시 적 업무 프리랜서 개발자 는 근로자 아냐 \"</td>\n",
              "      <td>김씨 는 2017년 7월 소프트웨어 개발 업체 구두 계약 체결 하고 프로그램 개발...</td>\n",
              "      <td>법원 은 김씨 근로자 아니라고 봤다. 이어 \" 김씨 회사 근로 계약 체결 하고자 했...</td>\n",
              "      <td>0.9402496814727783</td>\n",
              "      <td>0.9402496814727783</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>15</td>\n",
              "      <td>15</td>\n",
              "      <td>진화 된 음성인식 기술 ...' 놈 목소리 ' 꼼짝 마 !</td>\n",
              "      <td>검찰 관계자 는 \" 수사 과정 입수 한 녹음 파일 대해 목소리 아니라고 발뺌 하는...</td>\n",
              "      <td>검찰 관계자 는 \" 수사 과정 입수 한 녹음 파일 대해 목소리 아니라고 발뺌 하는 ...</td>\n",
              "      <td>0.9400198459625244</td>\n",
              "      <td>0.9400198459625244</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>16</td>\n",
              "      <td>16</td>\n",
              "      <td>서울 서 전시회 는 세계 적 디자이너 폴 스미스 \" 영감 · 개성 표 출하 는 법 ...</td>\n",
              "      <td>스미스 는 날 기자간담회 \" 10 대 , 대학생 디자이너 꿈꾸는 학생 많이 찾아와...</td>\n",
              "      <td>1970년 영국 노팅엄 9 m2 크기 공 방 시작 한 스미스 는 지난해 ( 2017...</td>\n",
              "      <td>0.9232895374298096</td>\n",
              "      <td>0.9232895374298096</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>17</td>\n",
              "      <td>17</td>\n",
              "      <td>법관 대표 회의 의장 ' 법 ' 출신</td>\n",
              "      <td>김 대법원 장 은 \" 재판 결과 일부 제기 하는 법관 개인 신상 이나 성향 대한 ...</td>\n",
              "      <td>날 회의 에서는 전국 급 법원 대표 판사 총 125 명 가운데 120 명 참석 해 ...</td>\n",
              "      <td>0.9354445934295654</td>\n",
              "      <td>0.9354445934295654</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>18</td>\n",
              "      <td>18</td>\n",
              "      <td>' 아이돌 룸 ' 헨리 X 볼 빨간 사춘기 , 음악 천재 ' 귀 호강 ' 콜라보</td>\n",
              "      <td>최근 진행 된 ' 아이돌 룸 ' 녹화 헨리 는 볼 빨간 사춘기 와의 인연 깜짝 공...</td>\n",
              "      <td>두 팀 은'음악 천재'다운 능력 한껏 뽐낼 수 있는'즉흥 창작 미션'도전 했다. 헨...</td>\n",
              "      <td>0.9347810745239258</td>\n",
              "      <td>0.9347810745239258</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>19</td>\n",
              "      <td>19</td>\n",
              "      <td>女 골프 ' 깃대 퍼팅 ' 전성 시대</td>\n",
              "      <td>고 진영 은 짧든 , 길든 대다수 퍼팅 깃대 꽂은 채 한다 . 고 진영 은 깃대 ...</td>\n",
              "      <td>지난 7일 끝난 한국 여자 프로 골프 ( KLPGA ) 투어 개막전 롯데 렌터카 오...</td>\n",
              "      <td>0.9101230502128601</td>\n",
              "      <td>0.9101230502128601</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f83b0783-6a58-49a4-ba15-ea206acc0783')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f83b0783-6a58-49a4-ba15-ea206acc0783 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f83b0783-6a58-49a4-ba15-ea206acc0783');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_tokenized_val_new = df_tokenized_val_new[['TITLE','text','model_answer_sentence','score']]"
      ],
      "metadata": {
        "id": "nxkohpdNsqRx"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drop_idx_list=[]\n",
        "for i in tqdm(range(len(df_tokenized_val_new))):\n",
        "    try: df_tokenized_val_new['score'].iloc[i] = float(df_tokenized_val_new['score'].iloc[i])\n",
        "    except:\n",
        "        drop_idx_list.append(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ju3RDcHGtAqE",
        "outputId": "56718b56-17ef-4c56-a2bc-d0b5347b74a8"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 19764/19764 [00:04<00:00, 4717.98it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(drop_idx_list))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BkBfKARytwdK",
        "outputId": "303f8971-0b0d-45cb-cc60-8cdb67af308e"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "233\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_tokenized_val_new.iloc[drop_idx_list[3]]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jjv-Vg0Et4zW",
        "outputId": "9967c34e-4eb2-43b0-b9bc-e67328ac9521"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TITLE                                        여야 5 당 원내대표 , 4월 국회 정상화 합의 실패\n",
              "text                      여야 원내대표 은 여야 대립 경색 된 대치 정국 해법 마련 하고자 모였으나 뚜렷한...\n",
              "model_answer_sentence                                       error_sentence\n",
              "score                     여야 원내대표 은 여야 대립 경색 된 대치 정국 해법 마련 하고자 모였으나 뚜렷한...\n",
              "Name: 1610, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_tokenized_val_new = df_tokenized_val_new.drop(drop_idx_list)"
      ],
      "metadata": {
        "id": "4Z8GS4ZUuJaQ"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_tokenized_val_new['score'].describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v3PbyKDY3Wmh",
        "outputId": "78b2b210-b005-4f45-c01a-d83bec9e01a4"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count     19531.000000\n",
              "unique    19304.000000\n",
              "top           0.928657\n",
              "freq          3.000000\n",
              "Name: score, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.hist(df_tokenized_val_new['score'])\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "TnyW726FuUv0",
        "outputId": "3e7d5598-88bb-4979-fd7c-22ea0a09af11"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_tokenized_val_new[:10000].to_csv(\"/content/drive/MyDrive/Summary_task/result_final.csv\",mode = 'w')"
      ],
      "metadata": {
        "id": "5-4gflrI45vP"
      },
      "execution_count": 58,
      "outputs": []
    }
  ]
}